{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions\n",
    "def extract_coordinates():\n",
    "    rows = []\n",
    "    #creating empty file in folder, I added the start_time in the name of the csv file, so that if a symbol appears many times in a video, it will still be created in two different csv files, just that they will have different starting times\n",
    "    csv_file = f\"demo.csv\"\n",
    "    # if os.path.exists(csv_file):\n",
    "    #     return \n",
    "\n",
    "\n",
    "\n",
    "# Setup CSV File for the videos\n",
    "# 21 right hand landmarks, 21 left hand landmarks, 33 pose landmarks\n",
    "    num_coords = 21 + 21 + 33\n",
    "    landmarks = []\n",
    "    for val in range(1, num_coords+1):\n",
    "        landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]\n",
    "    print(\"Initialized an empty landmarks of size:\", len(landmarks))\n",
    "\n",
    "    with open(csv_file, mode='w', newline='') as f:\n",
    "        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        csv_writer.writerow(landmarks)\n",
    "    \n",
    "    \n",
    "\n",
    "#working with each video\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if (cap.isOpened()== False): \n",
    "        print(\"Error opening video stream or file\")\n",
    "    # Read until video is completed\n",
    "    else: \n",
    "        with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "            while(cap.isOpened()):  \n",
    "                # Capture frame-by-frame\n",
    "                ret, image = cap.read() \n",
    "                if ret == True:\n",
    "                    # the BGR image to RGB.\n",
    "                    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "                    # To improve performance, optionally mark the image as not writeable to\n",
    "                    # pass by reference.\n",
    "                    image.flags.writeable = False\n",
    "\n",
    "                    #!results contains all the information about the image, in this case, we are looking at hands\n",
    "                    results = holistic.process(image)\n",
    "                    \n",
    "                    \n",
    "                    # Draw the hand annotations on the image.\n",
    "                    image.flags.writeable = True\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                    \n",
    "                    # Display the resulting frame\n",
    "                    # Right hand\n",
    "                    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                            mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                            mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                            )\n",
    "\n",
    "                    # Left Hand\n",
    "                    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                            mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                            mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                            )\n",
    "\n",
    "                    # Pose Detections\n",
    "                    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                            mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                            mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                            )\n",
    "                    cv2.imshow('Frame',image)\n",
    "                    # Press Q on keyboard to  exitx\n",
    "                    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                        frame_width = int(cap.get(3)) \n",
    "                        frame_height = int(cap.get(4)) \n",
    "                        \n",
    "                        size = (frame_width, frame_height) \n",
    "                        result = cv2.VideoWriter('test.mp4',  \n",
    "                         cv2.VideoWriter_fourcc(*'MJPG'), \n",
    "                         10, size) \n",
    "                        break\n",
    "                    # Export coordinates\n",
    "                    try:\n",
    "                        # Extract Pose landmarks\n",
    "                        if results.pose_landmarks:\n",
    "                            pose = results.pose_landmarks.landmark\n",
    "                            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "                        else:\n",
    "                            # continue\n",
    "                            pose_row=list(np.array([[0,0,0,0] for i in range(33)]).flatten())\n",
    "                        # Extract hands landmarks\n",
    "                        if results.right_hand_landmarks:\n",
    "                            right_hand = results.right_hand_landmarks.landmark\n",
    "                            right_hand_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in right_hand]).flatten())\n",
    "                        else:\n",
    "                            #If no right hand detected, then it writes 0 to the CSV file\n",
    "                            right_hand_row = list(np.array([[0,0,0,0] for i in range(21)]).flatten())\n",
    "                        if results.left_hand_landmarks:\n",
    "                            left_hand = results.left_hand_landmarks.landmark\n",
    "                            left_hand_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in left_hand]).flatten())\n",
    "                        else:\n",
    "                            #If no left hand detected, then it writes 0 to the CSV file\n",
    "                            left_hand_row = list(np.array([[0,0,0,0] for i in range(21)]).flatten())\n",
    "\n",
    "                        # Concate rows\n",
    "                        row = pose_row + right_hand_row + left_hand_row\n",
    "                        rows.append(row)\n",
    "\n",
    "                        # Export to CSV\n",
    "                        \n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        break\n",
    "                         \n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            # When everything done, release the video capture object\n",
    "            cap.release() \n",
    "\n",
    "\n",
    "            # Closes all the frames\n",
    "            cv2.destroyAllWindows()\n",
    "            with open(csv_file, mode='a', newline='') as f:\n",
    "                            csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                            for row in rows:\n",
    "                                csv_writer.writerow(row) \n",
    "            # return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized an empty landmarks of size: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "extract_coordinates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListNode:\n",
    "    def __init__(self, value=0, next=None):\n",
    "        self.value = value\n",
    "        self.next = next\n",
    "\n",
    "def reverse_linked_list(lst):\n",
    "    new_lst = None\n",
    "    while lst != None:\n",
    "        temp_list = ListNode(lst.value, new_lst)\n",
    "        new_lst = temp_list\n",
    "        lst = lst.next\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-hackathons",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
