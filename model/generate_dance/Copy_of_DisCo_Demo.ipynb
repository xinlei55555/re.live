{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Qu-pX4GDlgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44ff79d4-a19c-4edb-adec-d1436b82035b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jul  8 23:26:15 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    22W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Clone the github repo"
      ],
      "metadata": {
        "id": "N7Som16t69XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Wangt-CN/DisCo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKByNFtrfV7M",
        "outputId": "e5b86d37-badb-4aa6-adb3-3719b14d9c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'DisCo' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2. Install the package\n",
        "\n",
        "Ps: Most errors are due to the unsuccessful package installation, please check the installation carefully.\n"
      ],
      "metadata": {
        "id": "mpXDRYzO6rEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --user torch==1.12.1+cu113 torchvision==0.13.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install --user progressbar psutil pymongo simplejson yacs boto3 pyyaml ete3 easydict deprecated future django orderedset python-magic datasets h5py omegaconf einops ipdb\n",
        "!pip install --user --exists-action w -r DisCo/requirements.txt\n",
        "!pip install git+https://github.com/microsoft/azfuse.git\n",
        "\n",
        "## for acceleration\n",
        "!pip install --user deepspeed==0.6.3\n",
        "!pip install -v -U git+https://github.com/facebookresearch/xformers.git@main#egg=xformers"
      ],
      "metadata": {
        "id": "37UDwQVxfp4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Download the pretrained model\n",
        "Feel free to use our other [checkpoints](https://github.com/Wangt-CN/DisCo#model-checkpoint-google-cloud-tiktok-training-data-fid-fvd-188--more-tiktok-style-training-data-fid-fvd-157) or change to your own model"
      ],
      "metadata": {
        "id": "YkfPye5C7FDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/lambdalabs/sd-image-variations-diffusers\n",
        "!wget https://storage.googleapis.com/disco-checkpoint-share/checkpoint_ft/moretiktok_nocfg/mp_rank_00_model_states.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5FjMXqkh827",
        "outputId": "22add15e-c6a2-4993-fd41-e22f2467b036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-08 22:44:46--  https://storage.googleapis.com/disco-checkpoint-share/checkpoint_ft/moretiktok_nocfg/mp_rank_00_model_states.pt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.18.128, 142.250.145.128, 173.194.79.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.18.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4547478081 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘mp_rank_00_model_states.pt’\n",
            "\n",
            "mp_rank_00_model_st 100%[===================>]   4.23G  32.2MB/s    in 2m 31s  \n",
            "\n",
            "2023-07-08 22:47:18 (28.7 MB/s) - ‘mp_rank_00_model_states.pt’ saved [4547478081/4547478081]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Start Running"
      ],
      "metadata": {
        "id": "5-u3ohQt7o2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/DisCo')\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "n2knZKbPsxsj",
        "outputId": "55ca73c3-3e44-49af-eb98-8e339e31c4b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/DisCo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "os.environ[\"WANDB_ENABLE\"] = \"0\"\n",
        "\n",
        "from utils.wutils_ldm import *\n",
        "from agent import Agent_LDM, WarmupLinearLR, WarmupLinearConstantLR\n",
        "import torch\n",
        "from config import BasicArgs\n",
        "from utils.lib import *\n",
        "# from utils.args import parse_with_cf\n",
        "from utils.dist import dist_init\n",
        "from dataset.tsv_dataset import make_data_sampler, make_batch_data_sampler\n",
        "from finetune_sdm_yaml import get_loader_info, make_data_loader\n",
        "torch.multiprocessing.set_sharing_strategy('file_system')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "513HsIP_sHMW",
        "outputId": "11ad32f5-c377-481b-b41f-89637d60ac3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2023-07-08 23:59:50 <wutils_ldm.py:150> <module>] <utils.py>: Deep Learning Utils @ Chenfei Wu\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WANDB_ENABLE: 0\n",
            "2023-07-08 23:59:52,674.674 43664:common.py:1785 setup_yaml(): python 3 env\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2023-07-08 23:59:53 <wutils.py:132> <module>] <utils.py>: Deep Learning Utils @ Chenfei Wu\u001b[0m\n",
            "[2023-07-08 23:59:53 <wutils.py:132> <module>] <utils.py>: Deep Learning Utils @ Chenfei Wu\u001b[0m\n",
            "[2023-07-08 23:59:53 <__init__.py:71> BasicArgs] Detected unknown Node f3451ce6be71.\u001b[0m\n",
            "[2023-07-08 23:59:53 <__init__.py:71> BasicArgs] Detected unknown Node f3451ce6be71.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.args import sharedArgs\n",
        "manual_args = ['--cf', 'config/ref_attn_clip_combine_controlnet/app_demo_image_edit.py', '--eval_visu', 'True', '--root_dir', '/content/run_test', '--local_train_batch_size', '32', '--local_eval_batch_size', '32', '--log_dir', 'exp/tiktok_ft', '--epochs', '20', '--deepspeed', '--eval_step', '500',\n",
        "               '--save_step', '500', '--gradient_accumulate_steps', '1', '--learning_rate', '2e-4', '--fix_dist_seed', 'True', '--loss_target',\n",
        "               'noise', '--unet_unfreeze_type', 'all', '--guidance_scale', '3', '--refer_sdvae', 'True', '--ref_null_caption', 'False', '--combine_clip_local', 'True', '--combine_use_mask', 'True', '--conds', 'poses','masks', '--pretrained_model', '/content/mp_rank_00_model_states.pt', '--pretrained_model_path', '/content/sd-image-variations-diffusers', '--eval_save_filename', 'try']\n",
        "parsed_args = sharedArgs.parser.parse_args(args=manual_args)\n",
        "\n",
        "###### process the args #######\n",
        "if parsed_args.root_dir:\n",
        "    BasicArgs.root_dir = parsed_args.root_dir\n",
        "else:\n",
        "    parsed_args.root_dir = BasicArgs.root_dir\n",
        "parsed_args.pretrained_model_path = os.path.join(parsed_args.root_dir, parsed_args.pretrained_model_path)\n",
        "\n",
        "def parse_with_cf(parsed_args):\n",
        "    \"\"\"This function will set args based on the input config file.\n",
        "    (1) it only overwrites unset parameters,\n",
        "        i.e., these parameters not set from user command line input\n",
        "    (2) it also sets configs in the config file but declared in the parser\n",
        "    \"\"\"\n",
        "    # convert to EasyDict object,\n",
        "    # enabling access from attributes even for nested config\n",
        "    # e.g., args.train_datasets[0].name\n",
        "    args = edict(vars(parsed_args))\n",
        "    if os.path.exists(parsed_args.cf):\n",
        "        cf = import_filename(parsed_args.cf)\n",
        "        config_args = edict(vars(cf.Args))\n",
        "        override_keys = {arg[2:].split(\"=\")[0] for arg in manual_args\n",
        "                         if arg.startswith(\"--\")}\n",
        "        # import pdb;pdb.set_trace()\n",
        "        for k, v in config_args.items():\n",
        "            if k not in override_keys:\n",
        "                setattr(args, k, v)\n",
        "    else:\n",
        "        raise NotImplementedError('Config filename %s does not exist.' % args.cf)\n",
        "    return args\n",
        "\n",
        "args = parse_with_cf(parsed_args)\n",
        "\n",
        "args.n_gpu = T.cuda.device_count() # local size\n",
        "args.local_size = args.n_gpu\n",
        "if args.root_dir not in args.log_dir:\n",
        "    args.log_dir = os.path.join(args.root_dir, args.log_dir)\n",
        "if args.stepwise_sample_depth == -1:\n",
        "    args.interpolation = None\n",
        "    args.interpolate_mode = None\n",
        "if args.interpolation != \"interpolate\":\n",
        "    args.interpolate_mode = None\n",
        "\n",
        "assert args.eval_step > 0, \"eval_step must be positive\"\n",
        "assert args.save_step > 0, \"save_step must be positive\"\n",
        "\n",
        "dist_init(args)\n",
        "args.dist = args.distributed\n",
        "args.nodes = args.num_nodes\n",
        "args.world_size = args.num_gpus\n",
        "args.train_batch_size = args.local_train_batch_size * args.world_size\n",
        "args.eval_batch_size = args.local_eval_batch_size * args.world_size\n",
        "#############################################\n",
        "\n",
        "cf = import_filename(args.cf)\n",
        "Net, inner_collect_fn = cf.Net, cf.inner_collect_fn\n",
        "\n",
        "dataset_cf = import_filename(args.dataset_cf)\n",
        "BaseDataset = dataset_cf.BaseDataset\n",
        "\n",
        "# args = update_args(parsed_args, args)\n",
        "\n",
        "# init models\n",
        "logger.info('Building models...')\n",
        "model = Net(args)\n",
        "print(f\"Args: {edict(vars(args))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCuG7qZ3zjYi",
        "outputId": "30b7e8cc-b12a-45fa-c050-3e285fa828bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2023-07-08 23:59:59 <<ipython-input-3-ed4eaf604d1c>:69> <cell line: 69>] Building models...\u001b[0m\n",
            "[2023-07-08 23:59:59 <<ipython-input-3-ed4eaf604d1c>:69> <cell line: 69>] Building models...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "distributed training ... presumbly debug with 1 GPU\n",
            "Using seed 42 for rank 0\n",
            "Using seed 42 for torch.cuda\n",
            "Loading pre-trained image_encoder from /content/sd-image-variations-diffusers/image_encoder\n",
            "Loading pre-trained vae from /content/sd-image-variations-diffusers/vae\n",
            "Loading pre-trained unet from /content/sd-image-variations-diffusers/unet\n",
            "use sd vae to init the controlnet condition embedding\n",
            "Args: {'root_dir': '/content/run_test', 'cf': 'config/ref_attn_clip_combine_controlnet/app_demo_image_edit.py', 'pretrained_model': '/content/mp_rank_00_model_states.pt', 'pretrained_model_lora': None, 'pretrained_model_controlnet': None, 'debug': False, 'debug_seed': False, 'debug_dataloader': False, 'log_dir': '/content/run_test/exp/tiktok_ft', 'deepspeed': True, 'use_amp': False, 'seed': 42, 'fix_dist_seed': True, 'tiktok_data_root': 'keli/dataset/TikTok_dataset/', 'img_size': [256, 256], 'max_video_len': 1, 'debug_max_video_len': 1, 'conds': ['poses', 'masks'], 'gradient_checkpointing': True, 'find_unused_parameters': False, 'enable_xformers_memory_efficient_attention': True, 'trainable_modules': None, 'scale_factor': 0.18215, 'loss_target': 'noise', 'x0_steps': 200, 'pretrained_model_path': '/content/sd-image-variations-diffusers', 'num_workers': 4, 'node_split_sampler': False, 'gradient_accumulate_steps': 1, 'max_grad_norm': -1, 'learning_rate': 0.0002, 'decay': 0.001, 'warmup_ratio': 0.1, 'max_train_samples': None, 'debug_max_train_samples': 100, 'drop_text': 1.0, 'local_train_batch_size': 32, 'epochs': 20, 'eval_step': 500.0, 'save_step': 500.0, 'do_train': False, 'train_yaml': './blob_dir/debug_output/video_sythesis/dataset/composite/train_webvid10m_a_54.yaml', 'resume': False, 'null_caption': False, 'refer_sdvae': True, 'controlnet_conditioning_scale_cond': 1.0, 'controlnet_conditioning_scale_ref': 1.0, 'unet_unfreeze_type': 'all', 'controlnet_attn': False, 'use_cfg': False, 'refer_clip_preprocess': False, 'refer_clip_proj': False, 'ref_null_caption': False, 'combine_clip_local': True, 'combine_use_mask': True, 'drop_ref': 0.0, 'my_adapter': False, 'pos_resize_img': False, 'fg_variation': 0.0, 'strong_aug_stage2': False, 'strong_rand_stage2': False, 'strong_aug_stage1': False, 'stage1_pretrain_path': None, 'stage2_only_pose': False, 'constant_lr': False, 'SD2_not_add_image_emb_noise': False, 'val_yaml': './blob_dir/debug_output/video_sythesis/dataset/composite/val_webvid10m_a.yaml', 'max_eval_samples': None, 'debug_max_eval_samples': 20, 'pose_normalize': False, 'normalize_by_1st_frm': False, 'local_eval_batch_size': 32, 'eval_visu': True, 'eval_visu_trainsample': False, 'eval_visu_imagefolder': False, 'eval_visu_changepose': False, 'eval_visu_changefore': False, 'eval_save_filename': 'try', 'eval_before_train': True, 'eval_scheduler': 'ddim', 'eval_enc_dec_only': False, 'num_inf_videos_per_prompt': 1, 'num_inference_steps': 50, 'guidance_scale': 3.0, 'stepwise_sample_depth': -1, 'interpolation': None, 'interpolate_mode': None, 'visu_save': False, 'freeze_pose': False, 'freeze_background': False, 'ft_img_num': 0, 'ft_one_ref_image': True, 'ft_iters': None, 's1': 1.0, 's2': 1.0, 'ft_idx': None, 'ref_mode': 'first', '__module__': 'mymodule', 'task_name': 'ref_attn_clip_combine_controlnet', 'method_name': 'app_demo_image_edit', 'dataset_cf': 'dataset/app_demo_human_image_edit_singleinput.py', 'img_full_size': [256, 256], 'fps': 5, 'data_dir': './blob_dir/data/mtp_vlp_ray/debug/debug_pretrain', 'debug_train_yaml': './blob_dir/data/mtp_vlp_ray/debug/debug_pretrain/composite/train_webvid2.5m_2.yaml', 'debug_val_yaml': './blob_dir/data/mtp_vlp_ray/debug/debug_pretrain/composite/val_webvid2.5m.yaml', 'web_data_root': '/datadrive_d/wangtan/azure_storage/vigstandard_data/linjli/debug_output/video_sythesis/dataset/Lindsey_0504_youtube/frames/single_person', 'sd15_path': '/content/run_test/diffusers/stable-diffusion-v1-5-2', 'freeze_unet': True, 'num_inf_images_per_prompt': 1, '__doc__': None, 'n_gpu': 1, 'local_size': 1, 'num_gpus': 1, 'distributed': True, 'num_nodes': 1, 'word_size': 1, 'local_rank': 0, 'rank': 0, 'node_id': 0, 'dist': True, 'nodes': 1, 'world_size': 1, 'train_batch_size': 32, 'eval_batch_size': 32}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logger.warning(\"Do eval_visu...\")\n",
        "if getattr(args, 'refer_clip_preprocess', None):\n",
        "    eval_dataset = BaseDataset(args, args.val_yaml, split='val', preprocesser=model.feature_extractor)\n",
        "else:\n",
        "    eval_dataset = BaseDataset(args, args.val_yaml, split='val')\n",
        "eval_dataloader, eval_info = make_data_loader(\n",
        "    args, args.local_eval_batch_size,\n",
        "    eval_dataset)\n",
        "\n",
        "\n",
        "trainer = Agent_LDM(args=args, model=model)\n",
        "trainer.eval_demo_pre()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmhxcD304rY-",
        "outputId": "6bf849a9-384b-483d-efca-e6438377ac6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[33m[2023-07-09 00:00:49 <<ipython-input-4-a21f1cb1709e>:3> <cell line: 3>] Do eval_visu...\u001b[0m\n",
            "\u001b[33m[2023-07-09 00:00:49 <<ipython-input-4-a21f1cb1709e>:3> <cell line: 3>] Do eval_visu...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of samples: 25\n",
            "Specify the load model path, not use deepspeed but the pytorch original load func\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2023-07-09 00:01:11 <wutils_ldm.py:456> file2data] Loaded data from /content/mp_rank_00_model_states.pt\u001b[0m\n",
            "[2023-07-09 00:01:11 <wutils_ldm.py:456> file2data] Loaded data from /content/mp_rank_00_model_states.pt\u001b[0m\n",
            "\u001b[33m[2023-07-09 00:01:15 <wutils_ldm.py:701> adaptively_load_state_dict] Strictly Loaded state_dict.\u001b[0m\n",
            "\u001b[33m[2023-07-09 00:01:15 <wutils_ldm.py:701> adaptively_load_state_dict] Strictly Loaded state_dict.\u001b[0m\n",
            "\u001b[33m[2023-07-09 00:01:15 <agent.py:808> load_checkpoint_for_deepspeed_diff_gpu] Loaded checkpoint /content/mp_rank_00_model_states.pt of global_step 7200\u001b[0m\n",
            "\u001b[33m[2023-07-09 00:01:15 <agent.py:808> load_checkpoint_for_deepspeed_diff_gpu] Loaded checkpoint /content/mp_rank_00_model_states.pt of global_step 7200\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-07-09 00:01:16,138] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed info: version=0.6.3, git-hash=unknown, git-branch=unknown\n",
            "[2023-07-09 00:01:16,445] [INFO] [engine.py:278:__init__] DeepSpeed Flops Profiler Enabled: False\n",
            "[2023-07-09 00:01:16,455] [INFO] [config.py:1059:print] DeepSpeedEngine configuration:\n",
            "[2023-07-09 00:01:16,458] [INFO] [config.py:1063:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2023-07-09 00:01:16,460] [INFO] [config.py:1063:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2023-07-09 00:01:16,462] [INFO] [config.py:1063:print]   amp_enabled .................. False\n",
            "[2023-07-09 00:01:16,464] [INFO] [config.py:1063:print]   amp_params ................... False\n",
            "[2023-07-09 00:01:16,467] [INFO] [config.py:1063:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": null, \n",
            "    \"exps_dir\": null, \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2023-07-09 00:01:16,468] [INFO] [config.py:1063:print]   bfloat16_enabled ............. False\n",
            "[2023-07-09 00:01:16,469] [INFO] [config.py:1063:print]   checkpoint_tag_validation_enabled  True\n",
            "[2023-07-09 00:01:16,470] [INFO] [config.py:1063:print]   checkpoint_tag_validation_fail  False\n",
            "[2023-07-09 00:01:16,472] [INFO] [config.py:1063:print]   communication_data_type ...... None\n",
            "[2023-07-09 00:01:16,473] [INFO] [config.py:1063:print]   curriculum_enabled ........... False\n",
            "[2023-07-09 00:01:16,474] [INFO] [config.py:1063:print]   curriculum_params ............ False\n",
            "[2023-07-09 00:01:16,475] [INFO] [config.py:1063:print]   dataloader_drop_last ......... False\n",
            "[2023-07-09 00:01:16,476] [INFO] [config.py:1063:print]   disable_allgather ............ False\n",
            "[2023-07-09 00:01:16,477] [INFO] [config.py:1063:print]   dump_state ................... False\n",
            "[2023-07-09 00:01:16,478] [INFO] [config.py:1063:print]   dynamic_loss_scale_args ...... None\n",
            "[2023-07-09 00:01:16,479] [INFO] [config.py:1063:print]   eigenvalue_enabled ........... False\n",
            "[2023-07-09 00:01:16,479] [INFO] [config.py:1063:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2023-07-09 00:01:16,480] [INFO] [config.py:1063:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2023-07-09 00:01:16,481] [INFO] [config.py:1063:print]   eigenvalue_layer_num ......... 0\n",
            "[2023-07-09 00:01:16,482] [INFO] [config.py:1063:print]   eigenvalue_max_iter .......... 100\n",
            "[2023-07-09 00:01:16,483] [INFO] [config.py:1063:print]   eigenvalue_stability ......... 1e-06\n",
            "[2023-07-09 00:01:16,484] [INFO] [config.py:1063:print]   eigenvalue_tol ............... 0.01\n",
            "[2023-07-09 00:01:16,485] [INFO] [config.py:1063:print]   eigenvalue_verbose ........... False\n",
            "[2023-07-09 00:01:16,486] [INFO] [config.py:1063:print]   elasticity_enabled ........... False\n",
            "[2023-07-09 00:01:16,487] [INFO] [config.py:1063:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 3, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2023-07-09 00:01:16,488] [INFO] [config.py:1063:print]   fp16_enabled ................. True\n",
            "[2023-07-09 00:01:16,489] [INFO] [config.py:1063:print]   fp16_master_weights_and_gradients  False\n",
            "[2023-07-09 00:01:16,490] [INFO] [config.py:1063:print]   fp16_mixed_quantize .......... False\n",
            "[2023-07-09 00:01:16,491] [INFO] [config.py:1063:print]   global_rank .................. 0\n",
            "[2023-07-09 00:01:16,492] [INFO] [config.py:1063:print]   gradient_accumulation_steps .. 1\n",
            "[2023-07-09 00:01:16,493] [INFO] [config.py:1063:print]   gradient_clipping ............ 0.0\n",
            "[2023-07-09 00:01:16,494] [INFO] [config.py:1063:print]   gradient_predivide_factor .... 1.0\n",
            "[2023-07-09 00:01:16,494] [INFO] [config.py:1063:print]   initial_dynamic_scale ........ 4294967296\n",
            "[2023-07-09 00:01:16,496] [INFO] [config.py:1063:print]   loss_scale ................... 0\n",
            "[2023-07-09 00:01:16,497] [INFO] [config.py:1063:print]   memory_breakdown ............. False\n",
            "[2023-07-09 00:01:16,498] [INFO] [config.py:1063:print]   optimizer_legacy_fusion ...... False\n",
            "[2023-07-09 00:01:16,499] [INFO] [config.py:1063:print]   optimizer_name ............... None\n",
            "[2023-07-09 00:01:16,500] [INFO] [config.py:1063:print]   optimizer_params ............. None\n",
            "[2023-07-09 00:01:16,501] [INFO] [config.py:1063:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
            "[2023-07-09 00:01:16,502] [INFO] [config.py:1063:print]   pld_enabled .................. False\n",
            "[2023-07-09 00:01:16,502] [INFO] [config.py:1063:print]   pld_params ................... False\n",
            "[2023-07-09 00:01:16,503] [INFO] [config.py:1063:print]   prescale_gradients ........... False\n",
            "[2023-07-09 00:01:16,504] [INFO] [config.py:1063:print]   quantize_change_rate ......... 0.001\n",
            "[2023-07-09 00:01:16,506] [INFO] [config.py:1063:print]   quantize_groups .............. 1\n",
            "[2023-07-09 00:01:16,507] [INFO] [config.py:1063:print]   quantize_offset .............. 1000\n",
            "[2023-07-09 00:01:16,508] [INFO] [config.py:1063:print]   quantize_period .............. 1000\n",
            "[2023-07-09 00:01:16,509] [INFO] [config.py:1063:print]   quantize_rounding ............ 0\n",
            "[2023-07-09 00:01:16,510] [INFO] [config.py:1063:print]   quantize_start_bits .......... 16\n",
            "[2023-07-09 00:01:16,511] [INFO] [config.py:1063:print]   quantize_target_bits ......... 8\n",
            "[2023-07-09 00:01:16,512] [INFO] [config.py:1063:print]   quantize_training_enabled .... False\n",
            "[2023-07-09 00:01:16,513] [INFO] [config.py:1063:print]   quantize_type ................ 0\n",
            "[2023-07-09 00:01:16,514] [INFO] [config.py:1063:print]   quantize_verbose ............. False\n",
            "[2023-07-09 00:01:16,515] [INFO] [config.py:1063:print]   scheduler_name ............... None\n",
            "[2023-07-09 00:01:16,516] [INFO] [config.py:1063:print]   scheduler_params ............. None\n",
            "[2023-07-09 00:01:16,517] [INFO] [config.py:1063:print]   sparse_attention ............. None\n",
            "[2023-07-09 00:01:16,518] [INFO] [config.py:1063:print]   sparse_gradients_enabled ..... False\n",
            "[2023-07-09 00:01:16,519] [INFO] [config.py:1063:print]   steps_per_print .............. 10\n",
            "[2023-07-09 00:01:16,520] [INFO] [config.py:1063:print]   tensorboard_enabled .......... True\n",
            "[2023-07-09 00:01:16,521] [INFO] [config.py:1063:print]   tensorboard_job_name ......... tensorboard_log\n",
            "[2023-07-09 00:01:16,522] [INFO] [config.py:1063:print]   tensorboard_output_path ...... /content/run_test/exp/tiktok_ft\n",
            "[2023-07-09 00:01:16,523] [INFO] [config.py:1063:print]   train_batch_size ............. 32\n",
            "[2023-07-09 00:01:16,524] [INFO] [config.py:1063:print]   train_micro_batch_size_per_gpu  32\n",
            "[2023-07-09 00:01:16,525] [INFO] [config.py:1063:print]   use_quantizer_kernel ......... False\n",
            "[2023-07-09 00:01:16,526] [INFO] [config.py:1063:print]   wall_clock_breakdown ......... False\n",
            "[2023-07-09 00:01:16,527] [INFO] [config.py:1063:print]   world_size ................... 1\n",
            "[2023-07-09 00:01:16,528] [INFO] [config.py:1063:print]   zero_allow_untested_optimizer  False\n",
            "[2023-07-09 00:01:16,529] [INFO] [config.py:1063:print]   zero_config .................. {\n",
            "    \"stage\": 0, \n",
            "    \"contiguous_gradients\": true, \n",
            "    \"reduce_scatter\": true, \n",
            "    \"reduce_bucket_size\": 5.000000e+08, \n",
            "    \"allgather_partitions\": true, \n",
            "    \"allgather_bucket_size\": 5.000000e+08, \n",
            "    \"overlap_comm\": false, \n",
            "    \"load_from_fp32_weights\": true, \n",
            "    \"elastic_checkpoint\": false, \n",
            "    \"offload_param\": null, \n",
            "    \"offload_optimizer\": null, \n",
            "    \"sub_group_size\": 1.000000e+09, \n",
            "    \"prefetch_bucket_size\": 5.000000e+07, \n",
            "    \"param_persistence_threshold\": 1.000000e+05, \n",
            "    \"max_live_parameters\": 1.000000e+09, \n",
            "    \"max_reuse_distance\": 1.000000e+09, \n",
            "    \"gather_16bit_weights_on_model_save\": false, \n",
            "    \"ignore_unused_parameters\": true, \n",
            "    \"round_robin_gradients\": false, \n",
            "    \"legacy_stage1\": false\n",
            "}\n",
            "[2023-07-09 00:01:16,530] [INFO] [config.py:1063:print]   zero_enabled ................. False\n",
            "[2023-07-09 00:01:16,531] [INFO] [config.py:1063:print]   zero_optimization_stage ...... 0\n",
            "[2023-07-09 00:01:16,533] [INFO] [config.py:1065:print]   json = {\n",
            "    \"train_micro_batch_size_per_gpu\": 32, \n",
            "    \"gradient_accumulation_steps\": 1, \n",
            "    \"fp16\": {\n",
            "        \"enabled\": true\n",
            "    }, \n",
            "    \"flops_profiler\": {\n",
            "        \"enabled\": false, \n",
            "        \"profile_step\": 1, \n",
            "        \"module_depth\": -1, \n",
            "        \"top_modules\": 3, \n",
            "        \"detailed\": true\n",
            "    }, \n",
            "    \"tensorboard\": {\n",
            "        \"enabled\": true, \n",
            "        \"output_path\": \"/content/run_test/exp/tiktok_ft\", \n",
            "        \"job_name\": \"tensorboard_log\"\n",
            "    }\n",
            "}\n",
            "Using /root/.cache/torch_extensions/py310_cu113 as PyTorch extensions root...\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu113/utils/build.ninja...\n",
            "Building extension module utils...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.19990110397338867 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2023-07-09 00:01:18 <agent.py:237> prepare_dist_model] Successfully built models with {'trainable': 1581790996, 'frozen': 387620071, 'trainable_fp32': 0, 'trainalbe_fp16': 1581790996, 'frozen_fp32': 303966208, 'frozen_fp16': 83653863} parameters\u001b[0m\n",
            "[2023-07-09 00:01:18 <agent.py:237> prepare_dist_model] Successfully built models with {'trainable': 1581790996, 'frozen': 387620071, 'trainable_fp32': 0, 'trainalbe_fp16': 1581790996, 'frozen_fp32': 303966208, 'frozen_fp16': 83653863} parameters\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mode [all]: There are 686 modules in unet to be set as requires_grad=True.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(image):\n",
        "    if not image.mode == \"RGB\":\n",
        "        image = image.convert(\"RGB\")\n",
        "    return image\n",
        "\n",
        "@torch.no_grad()\n",
        "def inference(reference_fg, fg_mask, ref_bg_image, bg_mask, skeleton_img, *args, **kwargs):\n",
        "    reference_fg = load_image(reference_fg)\n",
        "    fg_mask = load_image(fg_mask)\n",
        "    ref_bg_image = load_image(ref_bg_image)\n",
        "    bg_mask = load_image(bg_mask)\n",
        "    skeleton_img = load_image(skeleton_img)\n",
        "\n",
        "    input_data = [reference_fg, fg_mask, ref_bg_image, bg_mask, skeleton_img]\n",
        "    output_image = trainer.eval_demo_run(input_data, eval_dataset=eval_dataset)\n",
        "    return output_image\n",
        "\n",
        "@torch.no_grad()\n",
        "def inference_masked(reference_fg, ref_bg_image, skeleton_img, *args, **kwargs):\n",
        "    reference_fg = load_image(reference_fg)\n",
        "    ref_bg_image = load_image(ref_bg_image)\n",
        "    skeleton_img = load_image(skeleton_img)\n",
        "\n",
        "    input_data = [reference_fg, ref_bg_image, skeleton_img]\n",
        "    output_image = trainer.eval_demo_run_masked(input_data, eval_dataset=eval_dataset)\n",
        "    return output_image"
      ],
      "metadata": {
        "id": "fF-xqrj95ekN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Launch the gradio demo"
      ],
      "metadata": {
        "id": "wv2ZhLq_77Ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import gradio as gr\n",
        "'''\n",
        "launch app\n",
        "'''\n",
        "title = \"DisCo Demo (Video Demo Comming Soon!)\"\n",
        "description = \"\"\"<p style='text-align: center'> <a href='https://disco-dance.github.io/' target='_blank'>Project Page</a> | <a href='https://arxiv.org/pdf/2212.11270.pdf' target='_blank'>Paper</a> | <a href='https://github.com/microsoft/X-Decoder' target='_blank'>Github Repo</a> | <a href='https://youtu.be/wYp6vmyolqE' target='_blank'>Video</a> </p>\n",
        "<p>Skip the queue by duplicating this space and upgrading to GPU in settings</p>\n",
        "<a href=\"https://huggingface.co/spaces/xdecoder/Demo?duplicate=true\"><img src=\"https://bit.ly/3gLdBN6\" alt=\"Duplicate Space\"></a>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    # DisCo Demo (Video Demo Comming Soon!)\n",
        "    Start edit the human with provided human foreground, background, pose.\n",
        "\n",
        "    Note that for self-uploaded images, TikTok-Style human images are preferred.\n",
        "\n",
        "    [Project Page](https://disco-dance.github.io/) | [Github](https://github.com/Wangt-CN/DisCo)\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row().style(equal_height=False):\n",
        "        with gr.Column(min_width=400, scale=2):\n",
        "            input_fg = gr.Image(type='pil',label=\"Foreground Image\")\n",
        "            gr.Examples(examples=[\"./demo_data/fg/masked_images/00035.png\", \"./demo_data/fg/masked_images/00335.png\", \"./demo_data/fg/masked_images/00147.png\", \"./demo_data/fg/masked_images/00072.png\", \"./demo_data/fg/masked_images/00115.png\"], inputs=input_fg)\n",
        "\n",
        "            input_bg = gr.Image(type='pil',label=\"Background Image\")\n",
        "            gr.Examples(examples=[\"./demo_data/bg/masked_images/00035.png\", \"./demo_data/bg/masked_images/00335.png\", \"./demo_data/bg/masked_images/00147.png\", \"./demo_data/bg/masked_images/00072.png\", \"./demo_data/bg/masked_images/00115.png\"], inputs=input_bg)\n",
        "\n",
        "            input_pose = gr.Image(type='pil',label=\"Target Pose\",scale=1)\n",
        "            gr.Examples(examples=[\"./demo_data/pose_img/0049.png\",\"./demo_data/pose_img/0198.png\",\"./demo_data/pose_img/0213.png\",\"./demo_data/pose_img/0264.png\",\"./demo_data/pose_img/0144.png\",\"./demo_data/pose_img/0054.png\"], inputs=input_pose)\n",
        "\n",
        "            btn = gr.Button(\"Generate\")\n",
        "\n",
        "\n",
        "        with gr.Column(min_width=150):\n",
        "            output_img = gr.Image(type='pil',label=\"Edited Human Image\")\n",
        "\n",
        "    btn.click(inference_masked, inputs=[input_fg, input_bg, input_pose], outputs=[output_img])\n",
        "\n",
        "demo.queue(concurrency_count=2)\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "yvs61CCg5iZV",
        "outputId": "a695e4b9-bc67-49c5-fb9d-9983648fd2ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-11e6eef69ecf>:31: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
            "  with gr.Row().style(equal_height=False):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://e249d08ffc1f80b5e5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e249d08ffc1f80b5e5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}