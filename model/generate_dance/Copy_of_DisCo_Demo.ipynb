{
<<<<<<< HEAD
<<<<<<< HEAD
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qu-pX4GDlgs",
        "outputId": "44ff79d4-a19c-4edb-adec-d1436b82035b"
      },
      "outputs": [],
      "source": [
        "# !nvidia-smi"
=======
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
=======
>>>>>>> d4049c1 (gitignore)
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qu-pX4GDlgs",
        "outputId": "44ff79d4-a19c-4edb-adec-d1436b82035b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
<<<<<<< HEAD
        "!nvidia-smi"
>>>>>>> 03730c0 (new changes)
=======
        "# !nvidia-smi"
>>>>>>> d4049c1 (gitignore)
      ]
    },
    {
      "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
      "metadata": {
        "id": "N7Som16t69XO"
      },
      "source": [
        "### 1. Clone the github repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
=======
      "source": [
        "### 1. Clone the github repo"
      ],
=======
>>>>>>> d4049c1 (gitignore)
      "metadata": {
        "id": "N7Som16t69XO"
      },
      "source": [
        "### 1. Clone the github repo"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "source": [
        "!git clone https://github.com/Wangt-CN/DisCo"
      ],
>>>>>>> 03730c0 (new changes)
=======
      "execution_count": 2,
>>>>>>> d4049c1 (gitignore)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKByNFtrfV7M",
        "outputId": "e5b86d37-badb-4aa6-adb3-3719b14d9c05"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "fatal: could not create work tree dir 'DisCo': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Wangt-CN/DisCo"
=======
      "execution_count": null,
=======
>>>>>>> d4049c1 (gitignore)
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'DisCo'...\n",
            "remote: Enumerating objects: 853, done.\u001b[K\n",
            "remote: Counting objects: 100% (110/110), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 853 (delta 64), reused 55 (delta 50), pack-reused 743\u001b[K\n",
            "Receiving objects: 100% (853/853), 98.36 MiB | 9.76 MiB/s, done.\n",
            "Resolving deltas: 100% (188/188), done.\n",
            "Updating files: 100% (681/681), done.\n"
          ]
        }
<<<<<<< HEAD
>>>>>>> 03730c0 (new changes)
=======
      ],
      "source": [
        "!git clone https://github.com/Wangt-CN/DisCo"
>>>>>>> d4049c1 (gitignore)
      ]
    },
    {
      "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
      "metadata": {
        "id": "mpXDRYzO6rEY"
      },
=======
>>>>>>> 03730c0 (new changes)
=======
      "metadata": {
        "id": "mpXDRYzO6rEY"
      },
>>>>>>> d4049c1 (gitignore)
      "source": [
        "\n",
        "### 2. Install the package\n",
        "\n",
        "Ps: Most errors are due to the unsuccessful package installation, please check the installation carefully.\n"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 23,
      "metadata": {
        "id": "37UDwQVxfp4T"
      },
      "outputs": [],
      "source": [
        "# !pip install --user torch==1.12.1+cu113 torchvision==0.13.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# !pip install --user progressbar psutil pymongo simplejson yacs boto3 pyyaml ete3 easydict deprecated future django orderedset python-magic datasets h5py omegaconf einops ipdb\n",
        "# !pip install --user --exists-action w -r DisCo/requirements.txt\n",
        "# !pip install git+https://github.com/microsoft/azfuse.git\n",
        "\n",
        "# # for acceleration\n",
        "# !pip install --user deepspeed==0.6.3\n",
        "# !pip install -v -U git+https://github.com/facebookresearch/xformers.git@main#egg=xformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkfPye5C7FDV"
      },
      "source": [
        "### 3. Download the pretrained model\n",
        "Feel free to use our other [checkpoints](https://github.com/Wangt-CN/DisCo#model-checkpoint-google-cloud-tiktok-training-data-fid-fvd-188--more-tiktok-style-training-data-fid-fvd-157) or change to your own model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
=======
      ],
      "metadata": {
        "id": "mpXDRYzO6rEY"
      }
=======
      ]
>>>>>>> d4049c1 (gitignore)
    },
    {
      "cell_type": "code",
      "execution_count": null,
=======
      "execution_count": 3,
>>>>>>> 72281c2 (new changes)
      "metadata": {
        "id": "37UDwQVxfp4T"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.12.1+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torch-1.12.1%2Bcu113-cp39-cp39-linux_x86_64.whl (1837.7 MB)\n",
            "\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.8 GB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:01:14\u001b[0m^C\n",
            "\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.8 GB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:01:14\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting progressbar\n",
            "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[35 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m /home/violet/Programs/miniconda3/envs/ai_hackathon/lib/python3.9/site-packages/setuptools/dist.py:804: SetuptoolsDeprecationWarning: Deprecated API usage.\n",
            "  \u001b[31m   \u001b[0m !!\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
            "  \u001b[31m   \u001b[0m         As setuptools moves its configuration towards `pyproject.toml`,\n",
            "  \u001b[31m   \u001b[0m         `setuptools.config.parse_configuration` became deprecated.\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m         For the time being, you can use the `setuptools.config.setupcfg` module\n",
            "  \u001b[31m   \u001b[0m         to access a backward compatible API, but this module is provisional\n",
            "  \u001b[31m   \u001b[0m         and might be removed in the future.\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m         To read project metadata, consider using\n",
            "  \u001b[31m   \u001b[0m         ``build.util.project_wheel_metadata`` (https://pypi.org/project/build/).\n",
            "  \u001b[31m   \u001b[0m         For simple scenarios, you can also try parsing the file directly\n",
            "  \u001b[31m   \u001b[0m         with the help of ``configparser``.\n",
            "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m !!\n",
            "  \u001b[31m   \u001b[0m   parse_configuration(\n",
            "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
            "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
            "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
            "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-8_hp5l3y/progressbar_63ecdf8f48554ce5ba5d0d3afe818b4c/setup.py\", line 19, in <module>\n",
            "  \u001b[31m   \u001b[0m     setup(\n",
            "  \u001b[31m   \u001b[0m   File \"/home/violet/Programs/miniconda3/envs/ai_hackathon/lib/python3.9/site-packages/setuptools/__init__.py\", line 152, in setup\n",
            "  \u001b[31m   \u001b[0m     _install_setup_requires(attrs)\n",
            "  \u001b[31m   \u001b[0m   File \"/home/violet/Programs/miniconda3/envs/ai_hackathon/lib/python3.9/site-packages/setuptools/__init__.py\", line 145, in _install_setup_requires\n",
            "  \u001b[31m   \u001b[0m     dist.parse_config_files(ignore_option_errors=True)\n",
            "  \u001b[31m   \u001b[0m   File \"/home/violet/Programs/miniconda3/envs/ai_hackathon/lib/python3.9/site-packages/setuptools/dist.py\", line 804, in parse_config_files\n",
            "  \u001b[31m   \u001b[0m     parse_configuration(\n",
            "  \u001b[31m   \u001b[0m   File \"/home/violet/Programs/miniconda3/envs/ai_hackathon/lib/python3.9/site-packages/setuptools/config/__init__.py\", line 36, in _wrapper\n",
            "  \u001b[31m   \u001b[0m     return fn(*args, **kwargs)\n",
            "  \u001b[31m   \u001b[0m   File \"/home/violet/Programs/miniconda3/envs/ai_hackathon/lib/python3.9/site-packages/setuptools/config/setupcfg.py\", line 190, in parse_configuration\n",
            "  \u001b[31m   \u001b[0m     distribution._referenced_files.update(\n",
            "  \u001b[31m   \u001b[0m AttributeError: 'MinimalDistribution' object has no attribute '_referenced_files'\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting wandb (from -r DisCo/requirements.txt (line 1))\n",
            "  Obtaining dependency information for wandb from https://files.pythonhosted.org/packages/28/3b/f1485df03e33a390b833081693e56be9e62fef097a82c26ef615605f768d/wandb-0.16.2-py3-none-any.whl.metadata\n",
            "  Downloading wandb-0.16.2-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting ffmpeg-python (from -r DisCo/requirements.txt (line 2))\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: opencv-python in /home/violet/Programs/miniconda3/envs/ai_hackathon/lib/python3.9/site-packages (from -r DisCo/requirements.txt (line 3)) (4.8.0.76)\n",
            "Collecting timm (from -r DisCo/requirements.txt (line 4))\n",
            "  Obtaining dependency information for timm from https://files.pythonhosted.org/packages/01/a5/eeb717242343d9ca34e7de554a6c08d96a0cfc7005ece4f847b1753581a6/timm-0.9.12-py3-none-any.whl.metadata\n",
            "  Downloading timm-0.9.12-py3-none-any.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy==6.0.3 (from -r DisCo/requirements.txt (line 5))\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[35 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m /home/violet/Programs/miniconda3/envs/ai_hackathon/lib/python3.9/site-packages/setuptools/dist.py:804: SetuptoolsDeprecationWarning: Deprecated API usage.\n",
            "  \u001b[31m   \u001b[0m !!\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
            "  \u001b[31m   \u001b[0m         As setuptools moves its configuration towards `pyproject.toml`,\n",
            "  \u001b[31m   \u001b[0m         `setuptools.config.parse_configuration` became deprecated.\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m         For the time being, you can use the `setuptools.config.setupcfg` module\n",
            "  \u001b[31m   \u001b[0m         to access a backward compatible API, but this module is provisional\n",
            "  \u001b[31m   \u001b[0m         and might be removed in the future.\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m         To read project metadata, consider using\n",
            "  \u001b[31m   \u001b[0m         ``build.util.project_wheel_metadata`` (https://pypi.org/project/build/).\n",
            "  \u001b[31m   \u001b[0m         For simple scenarios, you can also try parsing the file directly\n",
            "  \u001b[31m   \u001b[0m         with the help of ``configparser``.\n",
            "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m !!\n",
            "  \u001b[31m   \u001b[0m   parse_configuration(\n",
            "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
            "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
            "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
            "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-9_mqct_e/ftfy_8d445ba6e3814943b98d9c6ddbb881c0/setup.py\", line 22, in <module>\n",
            "  \u001b[31m   \u001b[0m     setup(\n",
            "  \u001b[31m   \u001b[0m   File \"/home/violet/Programs/miniconda3/envs/ai_hackathon/lib/python3.9/site-packages/setuptools/__init__.py\", line 152, in setup\n",
            "  \u001b[31m   \u001b[0m     _install_setup_requires(attrs)\n",
            "  \u001b[31m   \u001b[0m   File \"/home/violet/Programs/miniconda3/envs/ai_hackathon/lib/python3.9/site-packages/setuptools/__init__.py\", line 145, in _install_setup_requires\n",
            "  \u001b[31m   \u001b[0m     dist.parse_config_files(ignore_option_errors=True)\n",
            "  \u001b[31m   \u001b[0m   File \"/home/violet/Programs/miniconda3/envs/ai_hackathon/lib/python3.9/site-packages/setuptools/dist.py\", line 804, in parse_config_files\n",
            "  \u001b[31m   \u001b[0m     parse_configuration(\n",
            "  \u001b[31m   \u001b[0m   File \"/home/violet/Programs/miniconda3/envs/ai_hackathon/lib/python3.9/site-packages/setuptools/config/__init__.py\", line 36, in _wrapper\n",
            "  \u001b[31m   \u001b[0m     return fn(*args, **kwargs)\n",
            "  \u001b[31m   \u001b[0m   File \"/home/violet/Programs/miniconda3/envs/ai_hackathon/lib/python3.9/site-packages/setuptools/config/setupcfg.py\", line 190, in parse_configuration\n",
            "  \u001b[31m   \u001b[0m     distribution._referenced_files.update(\n",
            "  \u001b[31m   \u001b[0m AttributeError: 'MinimalDistribution' object has no attribute '_referenced_files'\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting git+https://github.com/microsoft/azfuse.git\n",
            "  Cloning https://github.com/microsoft/azfuse.git to /tmp/pip-req-build-pxosihz_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/microsoft/azfuse.git /tmp/pip-req-build-pxosihz_\n",
            "  Resolved https://github.com/microsoft/azfuse.git to commit 3d2ff80d414e9a6cb6a4176d8c59eb70184ee31b\n",
            "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[35 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m /home/violet/Programs/miniconda3/envs/ai_hackathon/lib/python3.9/site-packages/setuptools/dist.py:804: SetuptoolsDeprecationWarning: Deprecated API usage.\n",
            "  \u001b[31m   \u001b[0m !!\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
            "  \u001b[31m   \u001b[0m         As setuptools moves its configuration towards `pyproject.toml`,\n",
            "  \u001b[31m   \u001b[0m         `setuptools.config.parse_configuration` became deprecated.\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m         For the time being, you can use the `setuptools.config.setupcfg` module\n",
            "  \u001b[31m   \u001b[0m         to access a backward compatible API, but this module is provisional\n",
            "  \u001b[31m   \u001b[0m         and might be removed in the future.\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m         To read project metadata, consider using\n",
            "  \u001b[31m   \u001b[0m         ``build.util.project_wheel_metadata`` (https://pypi.org/project/build/).\n",
            "  \u001b[31m   \u001b[0m         For simple scenarios, you can also try parsing the file directly\n",
            "  \u001b[31m   \u001b[0m         with the help of ``configparser``.\n",
            "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m !!\n",
            "  \u001b[31m   \u001b[0m   parse_configuration(\n",
            "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
            "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
            "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
            "  \u001b[31m   \u001b[0m   File \"/tmp/pip-req-build-pxosihz_/setup.py\", line 8, in <module>\n",
            "  \u001b[31m   \u001b[0m     setup(name='azfuse',\n",
            "  \u001b[31m   \u001b[0m   File \"/home/violet/Programs/miniconda3/envs/ai_hackathon/lib/python3.9/site-packages/setuptools/__init__.py\", line 152, in setup\n",
            "  \u001b[31m   \u001b[0m     _install_setup_requires(attrs)\n",
            "  \u001b[31m   \u001b[0m   File \"/home/violet/Programs/miniconda3/envs/ai_hackathon/lib/python3.9/site-packages/setuptools/__init__.py\", line 145, in _install_setup_requires\n",
            "  \u001b[31m   \u001b[0m     dist.parse_config_files(ignore_option_errors=True)\n",
            "  \u001b[31m   \u001b[0m   File \"/home/violet/Programs/miniconda3/envs/ai_hackathon/lib/python3.9/site-packages/setuptools/dist.py\", line 804, in parse_config_files\n",
            "  \u001b[31m   \u001b[0m     parse_configuration(\n",
            "  \u001b[31m   \u001b[0m   File \"/home/violet/Programs/miniconda3/envs/ai_hackathon/lib/python3.9/site-packages/setuptools/config/__init__.py\", line 36, in _wrapper\n",
            "  \u001b[31m   \u001b[0m     return fn(*args, **kwargs)\n",
            "  \u001b[31m   \u001b[0m   File \"/home/violet/Programs/miniconda3/envs/ai_hackathon/lib/python3.9/site-packages/setuptools/config/setupcfg.py\", line 190, in parse_configuration\n",
            "  \u001b[31m   \u001b[0m     distribution._referenced_files.update(\n",
            "  \u001b[31m   \u001b[0m AttributeError: 'MinimalDistribution' object has no attribute '_referenced_files'\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting deepspeed==0.6.3\n",
            "  Downloading deepspeed-0.6.3.tar.gz (554 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m554.6/554.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l"
          ]
        }
      ],
      "source": [
        "!pip install --user torch==1.12.1+cu113 torchvision==0.13.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install --user progressbar psutil pymongo simplejson yacs boto3 pyyaml ete3 easydict deprecated future django orderedset python-magic datasets h5py omegaconf einops ipdb\n",
        "!pip install --user --exists-action w -r DisCo/requirements.txt\n",
        "!pip install git+https://github.com/microsoft/azfuse.git\n",
        "\n",
        "## for acceleration\n",
        "!pip install --user deepspeed==0.6.3\n",
        "!pip install -v -U git+https://github.com/facebookresearch/xformers.git@main#egg=xformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkfPye5C7FDV"
      },
      "source": [
        "### 3. Download the pretrained model\n",
        "Feel free to use our other [checkpoints](https://github.com/Wangt-CN/DisCo#model-checkpoint-google-cloud-tiktok-training-data-fid-fvd-188--more-tiktok-style-training-data-fid-fvd-157) or change to your own model"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "source": [
        "!git clone https://huggingface.co/lambdalabs/sd-image-variations-diffusers\n",
        "!wget https://storage.googleapis.com/disco-checkpoint-share/checkpoint_ft/moretiktok_nocfg/mp_rank_00_model_states.pt"
      ],
>>>>>>> 03730c0 (new changes)
=======
      "execution_count": null,
>>>>>>> d4049c1 (gitignore)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5FjMXqkh827",
        "outputId": "22add15e-c6a2-4993-fd41-e22f2467b036"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [],
      "source": [
        "# !git clone https://huggingface.co/lambdalabs/sd-image-variations-diffusers\n",
        "# !wget https://storage.googleapis.com/disco-checkpoint-share/checkpoint_ft/moretiktok_nocfg/mp_rank_00_model_states.pt"
=======
      "execution_count": null,
=======
>>>>>>> d4049c1 (gitignore)
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-07-08 22:44:46--  https://storage.googleapis.com/disco-checkpoint-share/checkpoint_ft/moretiktok_nocfg/mp_rank_00_model_states.pt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.18.128, 142.250.145.128, 173.194.79.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.18.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4547478081 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘mp_rank_00_model_states.pt’\n",
            "\n",
            "mp_rank_00_model_st 100%[===================>]   4.23G  32.2MB/s    in 2m 31s  \n",
            "\n",
            "2023-07-08 22:47:18 (28.7 MB/s) - ‘mp_rank_00_model_states.pt’ saved [4547478081/4547478081]\n",
            "\n"
          ]
        }
<<<<<<< HEAD
>>>>>>> 03730c0 (new changes)
=======
      ],
      "source": [
        "!git clone https://huggingface.co/lambdalabs/sd-image-variations-diffusers\n",
        "!wget https://storage.googleapis.com/disco-checkpoint-share/checkpoint_ft/moretiktok_nocfg/mp_rank_00_model_states.pt"
>>>>>>> d4049c1 (gitignore)
      ]
    },
    {
      "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
      "metadata": {
        "id": "5-u3ohQt7o2c"
      },
      "source": [
        "### 4. Start Running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
=======
      "source": [
        "### 4. Start Running"
      ],
=======
>>>>>>> d4049c1 (gitignore)
      "metadata": {
        "id": "5-u3ohQt7o2c"
      },
      "source": [
        "### 4. Start Running"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "source": [
        "import os\n",
        "os.chdir('/content/DisCo')\n",
        "os.getcwd()"
      ],
>>>>>>> 03730c0 (new changes)
=======
      "execution_count": null,
>>>>>>> d4049c1 (gitignore)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "n2knZKbPsxsj",
        "outputId": "55ca73c3-3e44-49af-eb98-8e339e31c4b5"
      },
<<<<<<< HEAD
<<<<<<< HEAD
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/DisCo'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.chdir('/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/DisCo/')\n",
        "#when running this, you have to put the right folder.\n",
        "os.getcwd()"
=======
      "execution_count": null,
=======
>>>>>>> d4049c1 (gitignore)
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/DisCo'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
<<<<<<< HEAD
>>>>>>> 03730c0 (new changes)
=======
      ],
      "source": [
        "import os\n",
        "os.chdir('/content/DisCo')\n",
        "os.getcwd()"
>>>>>>> d4049c1 (gitignore)
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
=======
=======
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "513HsIP_sHMW",
        "outputId": "11ad32f5-c377-481b-b41f-89637d60ac3d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2023-07-08 23:59:50 <wutils_ldm.py:150> <module>] <utils.py>: Deep Learning Utils @ Chenfei Wu\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WANDB_ENABLE: 0\n",
            "2023-07-08 23:59:52,674.674 43664:common.py:1785 setup_yaml(): python 3 env\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2023-07-08 23:59:53 <wutils.py:132> <module>] <utils.py>: Deep Learning Utils @ Chenfei Wu\u001b[0m\n",
            "[2023-07-08 23:59:53 <wutils.py:132> <module>] <utils.py>: Deep Learning Utils @ Chenfei Wu\u001b[0m\n",
            "[2023-07-08 23:59:53 <__init__.py:71> BasicArgs] Detected unknown Node f3451ce6be71.\u001b[0m\n",
            "[2023-07-08 23:59:53 <__init__.py:71> BasicArgs] Detected unknown Node f3451ce6be71.\u001b[0m\n"
          ]
        }
      ],
>>>>>>> d4049c1 (gitignore)
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "os.environ[\"WANDB_ENABLE\"] = \"0\"\n",
        "\n",
        "from utils.wutils_ldm import *\n",
        "from agent import Agent_LDM, WarmupLinearLR, WarmupLinearConstantLR\n",
        "import torch\n",
        "from config import BasicArgs\n",
        "from utils.lib import *\n",
        "# from utils.args import parse_with_cf\n",
        "from utils.dist import dist_init\n",
        "from dataset.tsv_dataset import make_data_sampler, make_batch_data_sampler\n",
        "from finetune_sdm_yaml import get_loader_info, make_data_loader\n",
        "torch.multiprocessing.set_sharing_strategy('file_system')"
<<<<<<< HEAD
      ],
>>>>>>> 03730c0 (new changes)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "513HsIP_sHMW",
        "outputId": "11ad32f5-c377-481b-b41f-89637d60ac3d"
      },
<<<<<<< HEAD
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/DisCo\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "os.environ[\"WANDB_ENABLE\"] = \"0\"\n",
        "\n",
        "# going into this file and importing everything\n",
        "from DisCo.utils.wutils_ldm import *\n",
        "\n",
        "from DisCo.agent import Agent_LDM, WarmupLinearLR, WarmupLinearConstantLR\n",
        "import torch\n",
        "from DisCo.config.basicargs import BasicArgs #i modifified thid \n",
        "from DisCo.utils.lib import *\n",
        "from DisCo.utils.args import parse_with_cf\n",
        "from DisCo.utils.dist import dist_init\n",
        "from DisCo.dataset.tsv_dataset import make_data_sampler, make_batch_data_sampler\n",
        "from DisCo.finetune_sdm_yaml import get_loader_info, make_data_loader\n",
        "torch.multiprocessing.set_sharing_strategy('file_system')"
=======
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2023-07-08 23:59:50 <wutils_ldm.py:150> <module>] <utils.py>: Deep Learning Utils @ Chenfei Wu\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WANDB_ENABLE: 0\n",
            "2023-07-08 23:59:52,674.674 43664:common.py:1785 setup_yaml(): python 3 env\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2023-07-08 23:59:53 <wutils.py:132> <module>] <utils.py>: Deep Learning Utils @ Chenfei Wu\u001b[0m\n",
            "[2023-07-08 23:59:53 <wutils.py:132> <module>] <utils.py>: Deep Learning Utils @ Chenfei Wu\u001b[0m\n",
            "[2023-07-08 23:59:53 <__init__.py:71> BasicArgs] Detected unknown Node f3451ce6be71.\u001b[0m\n",
            "[2023-07-08 23:59:53 <__init__.py:71> BasicArgs] Detected unknown Node f3451ce6be71.\u001b[0m\n"
          ]
        }
>>>>>>> 03730c0 (new changes)
=======
>>>>>>> d4049c1 (gitignore)
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
      "execution_count": 31,
=======
      "execution_count": null,
>>>>>>> d4049c1 (gitignore)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCuG7qZ3zjYi",
        "outputId": "30b7e8cc-b12a-45fa-c050-3e285fa828bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "usage: ipykernel_launcher.py [-h] [--root_dir ROOT_DIR] --cf CF\n",
            "                             [--pretrained_model PRETRAINED_MODEL]\n",
            "                             [--pretrained_model_lora PRETRAINED_MODEL_LORA]\n",
            "                             [--pretrained_model_controlnet PRETRAINED_MODEL_CONTROLNET]\n",
            "                             [--debug [DEBUG]] [--debug_seed [DEBUG_SEED]]\n",
            "                             [--debug_dataloader [DEBUG_DATALOADER]]\n",
            "                             [--log_dir LOG_DIR] [--deepspeed [DEEPSPEED]]\n",
            "                             [--use_amp [USE_AMP]] [--seed SEED]\n",
            "                             [--fix_dist_seed [FIX_DIST_SEED]]\n",
            "                             [--tiktok_data_root TIKTOK_DATA_ROOT]\n",
            "                             [--img_size IMG_SIZE]\n",
            "                             [--max_video_len MAX_VIDEO_LEN]\n",
            "                             [--debug_max_video_len DEBUG_MAX_VIDEO_LEN]\n",
            "                             [--conds {poses,masks,densepose,hed,canny_100_200,midas,mlsd_0.1_0.1,uniformer} [{poses,masks,densepose,hed,canny_100_200,midas,mlsd_0.1_0.1,uniformer} ...]]\n",
            "                             [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]\n",
            "                             [--find_unused_parameters [FIND_UNUSED_PARAMETERS]]\n",
            "                             [--enable_xformers_memory_efficient_attention [ENABLE_XFORMERS_MEMORY_EFFICIENT_ATTENTION]]\n",
            "                             [--trainable_modules TRAINABLE_MODULES [TRAINABLE_MODULES ...]]\n",
            "                             [--scale_factor SCALE_FACTOR]\n",
            "                             [--loss_target {noise,x0,mixed}]\n",
            "                             [--x0_steps X0_STEPS]\n",
            "                             [--pretrained_model_path PRETRAINED_MODEL_PATH]\n",
            "                             [--num_workers NUM_WORKERS]\n",
            "                             [--node_split_sampler [NODE_SPLIT_SAMPLER]]\n",
            "                             [--gradient_accumulate_steps GRADIENT_ACCUMULATE_STEPS]\n",
            "                             [--max_grad_norm MAX_GRAD_NORM]\n",
            "                             [--learning_rate LEARNING_RATE] [--decay DECAY]\n",
            "                             [--warmup_ratio WARMUP_RATIO]\n",
            "                             [--max_train_samples MAX_TRAIN_SAMPLES]\n",
            "                             [--debug_max_train_samples DEBUG_MAX_TRAIN_SAMPLES]\n",
            "                             [--drop_text DROP_TEXT]\n",
            "                             [--local_train_batch_size LOCAL_TRAIN_BATCH_SIZE]\n",
            "                             [--epochs EPOCHS] [--eval_step EVAL_STEP]\n",
            "                             [--save_step SAVE_STEP] [--do_train [DO_TRAIN]]\n",
            "                             [--train_yaml TRAIN_YAML] [--resume [RESUME]]\n",
            "                             [--null_caption [NULL_CAPTION]]\n",
            "                             [--refer_sdvae [REFER_SDVAE]]\n",
            "                             [--controlnet_conditioning_scale_cond CONTROLNET_CONDITIONING_SCALE_COND]\n",
            "                             [--controlnet_conditioning_scale_ref CONTROLNET_CONDITIONING_SCALE_REF]\n",
            "                             [--nframes NFRAMES]\n",
            "                             [--frame_interval FRAME_INTERVAL]\n",
            "                             [--eval_sample_interval EVAL_SAMPLE_INTERVAL]\n",
            "                             [--train_sample_interval TRAIN_SAMPLE_INTERVAL]\n",
            "                             [--unet_unfreeze_type {crossattn-kv,crossattn,transblocks,all,null}]\n",
            "                             [--controlnet_attn [CONTROLNET_ATTN]]\n",
            "                             [--use_cfg [USE_CFG]]\n",
            "                             [--refer_clip_preprocess [REFER_CLIP_PREPROCESS]]\n",
            "                             [--refer_clip_proj [REFER_CLIP_PROJ]]\n",
            "                             [--ref_null_caption [REF_NULL_CAPTION]]\n",
            "                             [--combine_clip_local [COMBINE_CLIP_LOCAL]]\n",
            "                             [--combine_use_mask [COMBINE_USE_MASK]]\n",
            "                             [--drop_ref DROP_REF] [--my_adapter [MY_ADAPTER]]\n",
            "                             [--pos_resize_img [POS_RESIZE_IMG]]\n",
            "                             [--fg_variation FG_VARIATION]\n",
            "                             [--strong_aug_stage2 [STRONG_AUG_STAGE2]]\n",
            "                             [--strong_rand_stage2 [STRONG_RAND_STAGE2]]\n",
            "                             [--strong_aug_stage1 [STRONG_AUG_STAGE1]]\n",
            "                             [--stage1_pretrain_path STAGE1_PRETRAIN_PATH]\n",
            "                             [--stage2_only_pose [STAGE2_ONLY_POSE]]\n",
            "                             [--constant_lr [CONSTANT_LR]]\n",
            "                             [--SD2_not_add_image_emb_noise [SD2_NOT_ADD_IMAGE_EMB_NOISE]]\n",
            "                             [--val_yaml VAL_YAML]\n",
            "                             [--max_eval_samples MAX_EVAL_SAMPLES]\n",
            "                             [--debug_max_eval_samples DEBUG_MAX_EVAL_SAMPLES]\n",
            "                             [--pose_normalize [POSE_NORMALIZE]]\n",
            "                             [--normalize_by_1st_frm [NORMALIZE_BY_1ST_FRM]]\n",
            "                             [--local_eval_batch_size LOCAL_EVAL_BATCH_SIZE]\n",
            "                             [--eval_visu [EVAL_VISU]]\n",
            "                             [--eval_visu_trainsample [EVAL_VISU_TRAINSAMPLE]]\n",
            "                             [--eval_visu_imagefolder [EVAL_VISU_IMAGEFOLDER]]\n",
            "                             [--eval_visu_changepose [EVAL_VISU_CHANGEPOSE]]\n",
            "                             [--eval_visu_changefore [EVAL_VISU_CHANGEFORE]]\n",
            "                             [--eval_save_filename EVAL_SAVE_FILENAME]\n",
            "                             [--eval_before_train [EVAL_BEFORE_TRAIN]]\n",
            "                             [--eval_scheduler {pndms,ddpm,ddim}]\n",
            "                             [--eval_enc_dec_only [EVAL_ENC_DEC_ONLY]]\n",
            "                             [--num_inf_videos_per_prompt NUM_INF_VIDEOS_PER_PROMPT]\n",
            "                             [--num_inference_steps NUM_INFERENCE_STEPS]\n",
            "                             [--guidance_scale GUIDANCE_SCALE]\n",
            "                             [--stepwise_sample_depth STEPWISE_SAMPLE_DEPTH]\n",
            "                             [--interpolation {copy,average,interpolate,average_noise,None}]\n",
            "                             [--interpolate_mode {nearest,bilinear,trilinear,area,nearest-exact,None}]\n",
            "                             [--visu_save [VISU_SAVE]]\n",
            "                             [--freeze_pose [FREEZE_POSE]]\n",
            "                             [--freeze_background [FREEZE_BACKGROUND]]\n",
            "                             [--ft_img_num FT_IMG_NUM]\n",
            "                             [--ft_one_ref_image [FT_ONE_REF_IMAGE]]\n",
            "                             [--ft_iters FT_ITERS] [--s1 S1] [--s2 S2]\n",
            "                             [--ft_idx FT_IDX] [--ref_mode REF_MODE]\n",
            "ipykernel_launcher.py: error: argument --conds: invalid choice: 'model_pretrained.pt' (choose from 'poses', 'masks', 'densepose', 'hed', 'canny_100_200', 'midas', 'mlsd_0.1_0.1', 'uniformer')\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'tb_frame'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
            "File \u001b[0;32m~/Programs/miniconda3/envs/ai_hackathon2/lib/python3.10/argparse.py:1866\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1866\u001b[0m     namespace, args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_known_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ArgumentError:\n",
            "File \u001b[0;32m~/Programs/miniconda3/envs/ai_hackathon2/lib/python3.10/argparse.py:2079\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args\u001b[0;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[1;32m   2078\u001b[0m     \u001b[38;5;66;03m# consume the next optional and any arguments for it\u001b[39;00m\n\u001b[0;32m-> 2079\u001b[0m     start_index \u001b[38;5;241m=\u001b[39m \u001b[43mconsume_optional\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2081\u001b[0m \u001b[38;5;66;03m# consume any positionals following the last Optional\u001b[39;00m\n",
            "File \u001b[0;32m~/Programs/miniconda3/envs/ai_hackathon2/lib/python3.10/argparse.py:2019\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args.<locals>.consume_optional\u001b[0;34m(start_index)\u001b[0m\n\u001b[1;32m   2018\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action, args, option_string \u001b[38;5;129;01min\u001b[39;00m action_tuples:\n\u001b[0;32m-> 2019\u001b[0m     \u001b[43mtake_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moption_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2020\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stop\n",
            "File \u001b[0;32m~/Programs/miniconda3/envs/ai_hackathon2/lib/python3.10/argparse.py:1927\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args.<locals>.take_action\u001b[0;34m(action, argument_strings, option_string)\u001b[0m\n\u001b[1;32m   1926\u001b[0m seen_actions\u001b[38;5;241m.\u001b[39madd(action)\n\u001b[0;32m-> 1927\u001b[0m argument_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margument_strings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1929\u001b[0m \u001b[38;5;66;03m# error if this argument is not allowed with other previously\u001b[39;00m\n\u001b[1;32m   1930\u001b[0m \u001b[38;5;66;03m# seen arguments, assuming that actions that use the default\u001b[39;00m\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;66;03m# value don't really count as \"present\"\u001b[39;00m\n",
            "File \u001b[0;32m~/Programs/miniconda3/envs/ai_hackathon2/lib/python3.10/argparse.py:2482\u001b[0m, in \u001b[0;36mArgumentParser._get_values\u001b[0;34m(self, action, arg_strings)\u001b[0m\n\u001b[1;32m   2481\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value:\n\u001b[0;32m-> 2482\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;66;03m# return the converted value\u001b[39;00m\n",
            "File \u001b[0;32m~/Programs/miniconda3/envs/ai_hackathon2/lib/python3.10/argparse.py:2519\u001b[0m, in \u001b[0;36mArgumentParser._check_value\u001b[0;34m(self, action, value)\u001b[0m\n\u001b[1;32m   2518\u001b[0m msg \u001b[38;5;241m=\u001b[39m _(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalid choice: \u001b[39m\u001b[38;5;132;01m%(value)r\u001b[39;00m\u001b[38;5;124m (choose from \u001b[39m\u001b[38;5;132;01m%(choices)s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2519\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ArgumentError(action, msg \u001b[38;5;241m%\u001b[39m args)\n",
            "\u001b[0;31mArgumentError\u001b[0m: argument --conds: invalid choice: 'model_pretrained.pt' (choose from 'poses', 'masks', 'densepose', 'hed', 'canny_100_200', 'midas', 'mlsd_0.1_0.1', 'uniformer')",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "Cell \u001b[0;32mIn[31], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m manual_args \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--cf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/DisCo/config/ref_attn_clip_combine_controlnet/app_demo_image_edit.py\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--eval_visu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--root_dir\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/run_test\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--local_train_batch_size\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m32\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--local_eval_batch_size\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m32\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--log_dir\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp/tiktok_ft\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--epochs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m20\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--deepspeed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--eval_step\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m500\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--save_step\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m500\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--gradient_accumulate_steps\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--learning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2e-4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--fix_dist_seed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--loss_target\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoise\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--unet_unfreeze_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--guidance_scale\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--refer_sdvae\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--ref_null_caption\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFalse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--combine_clip_local\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--combine_use_mask\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--conds\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposes\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmasks\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_pretrained.pt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/pretrained-image-model/model_pretrained.pt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/sd-image-variations-diffusers\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--eval_save_filename\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtry\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m parsed_args \u001b[38;5;241m=\u001b[39m \u001b[43msharedArgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanual_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m###### process the args #######\u001b[39;00m\n",
            "File \u001b[0;32m~/Programs/miniconda3/envs/ai_hackathon2/lib/python3.10/argparse.py:1833\u001b[0m, in \u001b[0;36mArgumentParser.parse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1832\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_args\u001b[39m(\u001b[38;5;28mself\u001b[39m, args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1833\u001b[0m     args, argv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_known_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1834\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m argv:\n",
            "File \u001b[0;32m~/Programs/miniconda3/envs/ai_hackathon2/lib/python3.10/argparse.py:1869\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1868\u001b[0m         err \u001b[38;5;241m=\u001b[39m _sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m-> 1869\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/Programs/miniconda3/envs/ai_hackathon2/lib/python3.10/argparse.py:2594\u001b[0m, in \u001b[0;36mArgumentParser.error\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2593\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprog\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprog, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m: message}\n\u001b[0;32m-> 2594\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%(prog)s\u001b[39;49;00m\u001b[38;5;124;43m: error: \u001b[39;49m\u001b[38;5;132;43;01m%(message)s\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Programs/miniconda3/envs/ai_hackathon2/lib/python3.10/argparse.py:2581\u001b[0m, in \u001b[0;36mArgumentParser.exit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2580\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_print_message(message, _sys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m-> 2581\u001b[0m \u001b[43m_sys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mSystemExit\u001b[0m: 2",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "File \u001b[0;32m~/Programs/miniconda3/envs/ai_hackathon2/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2121\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[1;32m   2119\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2120\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 2121\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2122\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2125\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
            "File \u001b[0;32m~/Programs/miniconda3/envs/ai_hackathon2/lib/python3.10/site-packages/IPython/core/ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[1;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Programs/miniconda3/envs/ai_hackathon2/lib/python3.10/site-packages/IPython/core/ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 568\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
            "File \u001b[0;32m~/Programs/miniconda3/envs/ai_hackathon2/lib/python3.10/site-packages/IPython/core/ultratb.py:1435\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[0;32m-> 1435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Programs/miniconda3/envs/ai_hackathon2/lib/python3.10/site-packages/IPython/core/ultratb.py:1326\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1323\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
            "File \u001b[0;32m~/Programs/miniconda3/envs/ai_hackathon2/lib/python3.10/site-packages/IPython/core/ultratb.py:1173\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1166\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   1171\u001b[0m ):\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
            "File \u001b[0;32m~/Programs/miniconda3/envs/ai_hackathon2/lib/python3.10/site-packages/IPython/core/ultratb.py:1063\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m   1061\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[1;32m   1062\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1063\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m   1064\u001b[0m )\n\u001b[1;32m   1066\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1067\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
            "File \u001b[0;32m~/Programs/miniconda3/envs/ai_hackathon2/lib/python3.10/site-packages/IPython/core/ultratb.py:1131\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
          ]
        }
      ],
      "source": [
        "from DisCo.utils.args import sharedArgs\n",
        "manual_args = ['--cf', '/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/DisCo/config/ref_attn_clip_combine_controlnet/app_demo_image_edit.py', '--eval_visu', 'True', '--root_dir', '/content/run_test', '--local_train_batch_size', '32', '--local_eval_batch_size', '32', '--log_dir', 'exp/tiktok_ft', '--epochs', '20', '--deepspeed', '--eval_step', '500',\n",
        "               '--save_step', '500', '--gradient_accumulate_steps', '1', '--learning_rate', '2e-4', '--fix_dist_seed', 'True', '--loss_target',\n",
        "               'noise', '--unet_unfreeze_type', 'all', '--guidance_scale', '3', '--refer_sdvae', 'True', '--ref_null_caption', 'False', '--combine_clip_local', 'True', '--combine_use_mask', 'True', '--conds', 'poses','masks', 'model_pretrained.pt', '/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/pretrained-image-model/model_pretrained.pt', '/content/sd-image-variations-diffusers', '--eval_save_filename', 'try']\n",
=======
=======
            "[2023-07-08 23:59:59 <<ipython-input-3-ed4eaf604d1c>:69> <cell line: 69>] Building models...\u001b[0m\n",
            "[2023-07-08 23:59:59 <<ipython-input-3-ed4eaf604d1c>:69> <cell line: 69>] Building models...\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "distributed training ... presumbly debug with 1 GPU\n",
            "Using seed 42 for rank 0\n",
            "Using seed 42 for torch.cuda\n",
            "Loading pre-trained image_encoder from /content/sd-image-variations-diffusers/image_encoder\n",
            "Loading pre-trained vae from /content/sd-image-variations-diffusers/vae\n",
            "Loading pre-trained unet from /content/sd-image-variations-diffusers/unet\n",
            "use sd vae to init the controlnet condition embedding\n",
            "Args: {'root_dir': '/content/run_test', 'cf': 'config/ref_attn_clip_combine_controlnet/app_demo_image_edit.py', 'pretrained_model': '/content/mp_rank_00_model_states.pt', 'pretrained_model_lora': None, 'pretrained_model_controlnet': None, 'debug': False, 'debug_seed': False, 'debug_dataloader': False, 'log_dir': '/content/run_test/exp/tiktok_ft', 'deepspeed': True, 'use_amp': False, 'seed': 42, 'fix_dist_seed': True, 'tiktok_data_root': 'keli/dataset/TikTok_dataset/', 'img_size': [256, 256], 'max_video_len': 1, 'debug_max_video_len': 1, 'conds': ['poses', 'masks'], 'gradient_checkpointing': True, 'find_unused_parameters': False, 'enable_xformers_memory_efficient_attention': True, 'trainable_modules': None, 'scale_factor': 0.18215, 'loss_target': 'noise', 'x0_steps': 200, 'pretrained_model_path': '/content/sd-image-variations-diffusers', 'num_workers': 4, 'node_split_sampler': False, 'gradient_accumulate_steps': 1, 'max_grad_norm': -1, 'learning_rate': 0.0002, 'decay': 0.001, 'warmup_ratio': 0.1, 'max_train_samples': None, 'debug_max_train_samples': 100, 'drop_text': 1.0, 'local_train_batch_size': 32, 'epochs': 20, 'eval_step': 500.0, 'save_step': 500.0, 'do_train': False, 'train_yaml': './blob_dir/debug_output/video_sythesis/dataset/composite/train_webvid10m_a_54.yaml', 'resume': False, 'null_caption': False, 'refer_sdvae': True, 'controlnet_conditioning_scale_cond': 1.0, 'controlnet_conditioning_scale_ref': 1.0, 'unet_unfreeze_type': 'all', 'controlnet_attn': False, 'use_cfg': False, 'refer_clip_preprocess': False, 'refer_clip_proj': False, 'ref_null_caption': False, 'combine_clip_local': True, 'combine_use_mask': True, 'drop_ref': 0.0, 'my_adapter': False, 'pos_resize_img': False, 'fg_variation': 0.0, 'strong_aug_stage2': False, 'strong_rand_stage2': False, 'strong_aug_stage1': False, 'stage1_pretrain_path': None, 'stage2_only_pose': False, 'constant_lr': False, 'SD2_not_add_image_emb_noise': False, 'val_yaml': './blob_dir/debug_output/video_sythesis/dataset/composite/val_webvid10m_a.yaml', 'max_eval_samples': None, 'debug_max_eval_samples': 20, 'pose_normalize': False, 'normalize_by_1st_frm': False, 'local_eval_batch_size': 32, 'eval_visu': True, 'eval_visu_trainsample': False, 'eval_visu_imagefolder': False, 'eval_visu_changepose': False, 'eval_visu_changefore': False, 'eval_save_filename': 'try', 'eval_before_train': True, 'eval_scheduler': 'ddim', 'eval_enc_dec_only': False, 'num_inf_videos_per_prompt': 1, 'num_inference_steps': 50, 'guidance_scale': 3.0, 'stepwise_sample_depth': -1, 'interpolation': None, 'interpolate_mode': None, 'visu_save': False, 'freeze_pose': False, 'freeze_background': False, 'ft_img_num': 0, 'ft_one_ref_image': True, 'ft_iters': None, 's1': 1.0, 's2': 1.0, 'ft_idx': None, 'ref_mode': 'first', '__module__': 'mymodule', 'task_name': 'ref_attn_clip_combine_controlnet', 'method_name': 'app_demo_image_edit', 'dataset_cf': 'dataset/app_demo_human_image_edit_singleinput.py', 'img_full_size': [256, 256], 'fps': 5, 'data_dir': './blob_dir/data/mtp_vlp_ray/debug/debug_pretrain', 'debug_train_yaml': './blob_dir/data/mtp_vlp_ray/debug/debug_pretrain/composite/train_webvid2.5m_2.yaml', 'debug_val_yaml': './blob_dir/data/mtp_vlp_ray/debug/debug_pretrain/composite/val_webvid2.5m.yaml', 'web_data_root': '/datadrive_d/wangtan/azure_storage/vigstandard_data/linjli/debug_output/video_sythesis/dataset/Lindsey_0504_youtube/frames/single_person', 'sd15_path': '/content/run_test/diffusers/stable-diffusion-v1-5-2', 'freeze_unet': True, 'num_inf_images_per_prompt': 1, '__doc__': None, 'n_gpu': 1, 'local_size': 1, 'num_gpus': 1, 'distributed': True, 'num_nodes': 1, 'word_size': 1, 'local_rank': 0, 'rank': 0, 'node_id': 0, 'dist': True, 'nodes': 1, 'world_size': 1, 'train_batch_size': 32, 'eval_batch_size': 32}\n"
          ]
        }
      ],
>>>>>>> d4049c1 (gitignore)
      "source": [
        "from utils.args import sharedArgs\n",
        "manual_args = ['--cf', 'config/ref_attn_clip_combine_controlnet/app_demo_image_edit.py', '--eval_visu', 'True', '--root_dir', '/content/run_test', '--local_train_batch_size', '32', '--local_eval_batch_size', '32', '--log_dir', 'exp/tiktok_ft', '--epochs', '20', '--deepspeed', '--eval_step', '500',\n",
        "               '--save_step', '500', '--gradient_accumulate_steps', '1', '--learning_rate', '2e-4', '--fix_dist_seed', 'True', '--loss_target',\n",
        "               'noise', '--unet_unfreeze_type', 'all', '--guidance_scale', '3', '--refer_sdvae', 'True', '--ref_null_caption', 'False', '--combine_clip_local', 'True', '--combine_use_mask', 'True', '--conds', 'poses','masks', '--pretrained_model', '/content/mp_rank_00_model_states.pt', '--pretrained_model_path', '/content/sd-image-variations-diffusers', '--eval_save_filename', 'try']\n",
>>>>>>> 03730c0 (new changes)
        "parsed_args = sharedArgs.parser.parse_args(args=manual_args)\n",
        "\n",
        "###### process the args #######\n",
        "if parsed_args.root_dir:\n",
        "    BasicArgs.root_dir = parsed_args.root_dir\n",
        "else:\n",
        "    parsed_args.root_dir = BasicArgs.root_dir\n",
<<<<<<< HEAD
        "parsed_args.pretrained_model_path = r\"/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/pretrained-image-model/model_pretrained.pt\"\n",
        "#  os.path.join(parsed_args.root_dir, parsed_args.pretrained_model_path)\n",
=======
        "parsed_args.pretrained_model_path = os.path.join(parsed_args.root_dir, parsed_args.pretrained_model_path)\n",
>>>>>>> 03730c0 (new changes)
        "\n",
        "def parse_with_cf(parsed_args):\n",
        "    \"\"\"This function will set args based on the input config file.\n",
        "    (1) it only overwrites unset parameters,\n",
        "        i.e., these parameters not set from user command line input\n",
        "    (2) it also sets configs in the config file but declared in the parser\n",
        "    \"\"\"\n",
        "    # convert to EasyDict object,\n",
        "    # enabling access from attributes even for nested config\n",
        "    # e.g., args.train_datasets[0].name\n",
        "    args = edict(vars(parsed_args))\n",
        "    if os.path.exists(parsed_args.cf):\n",
        "        cf = import_filename(parsed_args.cf)\n",
        "        config_args = edict(vars(cf.Args))\n",
        "        override_keys = {arg[2:].split(\"=\")[0] for arg in manual_args\n",
        "                         if arg.startswith(\"--\")}\n",
        "        # import pdb;pdb.set_trace()\n",
        "        for k, v in config_args.items():\n",
        "            if k not in override_keys:\n",
        "                setattr(args, k, v)\n",
        "    else:\n",
        "        raise NotImplementedError('Config filename %s does not exist.' % args.cf)\n",
        "    return args\n",
        "\n",
        "args = parse_with_cf(parsed_args)\n",
        "\n",
        "args.n_gpu = T.cuda.device_count() # local size\n",
        "args.local_size = args.n_gpu\n",
        "if args.root_dir not in args.log_dir:\n",
        "    args.log_dir = os.path.join(args.root_dir, args.log_dir)\n",
        "if args.stepwise_sample_depth == -1:\n",
        "    args.interpolation = None\n",
        "    args.interpolate_mode = None\n",
        "if args.interpolation != \"interpolate\":\n",
        "    args.interpolate_mode = None\n",
        "\n",
        "assert args.eval_step > 0, \"eval_step must be positive\"\n",
        "assert args.save_step > 0, \"save_step must be positive\"\n",
        "\n",
        "dist_init(args)\n",
        "args.dist = args.distributed\n",
        "args.nodes = args.num_nodes\n",
        "args.world_size = args.num_gpus\n",
        "args.train_batch_size = args.local_train_batch_size * args.world_size\n",
        "args.eval_batch_size = args.local_eval_batch_size * args.world_size\n",
        "#############################################\n",
        "\n",
        "cf = import_filename(args.cf)\n",
        "Net, inner_collect_fn = cf.Net, cf.inner_collect_fn\n",
        "\n",
        "dataset_cf = import_filename(args.dataset_cf)\n",
        "BaseDataset = dataset_cf.BaseDataset\n",
        "\n",
        "# args = update_args(parsed_args, args)\n",
        "\n",
        "# init models\n",
        "logger.info('Building models...')\n",
        "model = Net(args)\n",
        "print(f\"Args: {edict(vars(args))}\")"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
=======
      ],
>>>>>>> 03730c0 (new changes)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< HEAD
        "id": "OmhxcD304rY-",
        "outputId": "6bf849a9-384b-483d-efca-e6438377ac6d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[33m[2024-01-26 23:52:19 <2716821498.py:1> <module>] Do eval_visu...\u001b[0m\n",
            "\u001b[33m[2024-01-26 23:52:19 <2716821498.py:1> <module>] Do eval_visu...\u001b[0m\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'args' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDo eval_visu...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43margs\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrefer_clip_preprocess\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      3\u001b[0m     eval_dataset \u001b[38;5;241m=\u001b[39m BaseDataset(args, args\u001b[38;5;241m.\u001b[39mval_yaml, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocesser\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfeature_extractor)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
          ]
        }
      ],
=======
        "id": "pCuG7qZ3zjYi",
        "outputId": "30b7e8cc-b12a-45fa-c050-3e285fa828bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2023-07-08 23:59:59 <<ipython-input-3-ed4eaf604d1c>:69> <cell line: 69>] Building models...\u001b[0m\n",
            "[2023-07-08 23:59:59 <<ipython-input-3-ed4eaf604d1c>:69> <cell line: 69>] Building models...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "distributed training ... presumbly debug with 1 GPU\n",
            "Using seed 42 for rank 0\n",
            "Using seed 42 for torch.cuda\n",
            "Loading pre-trained image_encoder from /content/sd-image-variations-diffusers/image_encoder\n",
            "Loading pre-trained vae from /content/sd-image-variations-diffusers/vae\n",
            "Loading pre-trained unet from /content/sd-image-variations-diffusers/unet\n",
            "use sd vae to init the controlnet condition embedding\n",
            "Args: {'root_dir': '/content/run_test', 'cf': 'config/ref_attn_clip_combine_controlnet/app_demo_image_edit.py', 'pretrained_model': '/content/mp_rank_00_model_states.pt', 'pretrained_model_lora': None, 'pretrained_model_controlnet': None, 'debug': False, 'debug_seed': False, 'debug_dataloader': False, 'log_dir': '/content/run_test/exp/tiktok_ft', 'deepspeed': True, 'use_amp': False, 'seed': 42, 'fix_dist_seed': True, 'tiktok_data_root': 'keli/dataset/TikTok_dataset/', 'img_size': [256, 256], 'max_video_len': 1, 'debug_max_video_len': 1, 'conds': ['poses', 'masks'], 'gradient_checkpointing': True, 'find_unused_parameters': False, 'enable_xformers_memory_efficient_attention': True, 'trainable_modules': None, 'scale_factor': 0.18215, 'loss_target': 'noise', 'x0_steps': 200, 'pretrained_model_path': '/content/sd-image-variations-diffusers', 'num_workers': 4, 'node_split_sampler': False, 'gradient_accumulate_steps': 1, 'max_grad_norm': -1, 'learning_rate': 0.0002, 'decay': 0.001, 'warmup_ratio': 0.1, 'max_train_samples': None, 'debug_max_train_samples': 100, 'drop_text': 1.0, 'local_train_batch_size': 32, 'epochs': 20, 'eval_step': 500.0, 'save_step': 500.0, 'do_train': False, 'train_yaml': './blob_dir/debug_output/video_sythesis/dataset/composite/train_webvid10m_a_54.yaml', 'resume': False, 'null_caption': False, 'refer_sdvae': True, 'controlnet_conditioning_scale_cond': 1.0, 'controlnet_conditioning_scale_ref': 1.0, 'unet_unfreeze_type': 'all', 'controlnet_attn': False, 'use_cfg': False, 'refer_clip_preprocess': False, 'refer_clip_proj': False, 'ref_null_caption': False, 'combine_clip_local': True, 'combine_use_mask': True, 'drop_ref': 0.0, 'my_adapter': False, 'pos_resize_img': False, 'fg_variation': 0.0, 'strong_aug_stage2': False, 'strong_rand_stage2': False, 'strong_aug_stage1': False, 'stage1_pretrain_path': None, 'stage2_only_pose': False, 'constant_lr': False, 'SD2_not_add_image_emb_noise': False, 'val_yaml': './blob_dir/debug_output/video_sythesis/dataset/composite/val_webvid10m_a.yaml', 'max_eval_samples': None, 'debug_max_eval_samples': 20, 'pose_normalize': False, 'normalize_by_1st_frm': False, 'local_eval_batch_size': 32, 'eval_visu': True, 'eval_visu_trainsample': False, 'eval_visu_imagefolder': False, 'eval_visu_changepose': False, 'eval_visu_changefore': False, 'eval_save_filename': 'try', 'eval_before_train': True, 'eval_scheduler': 'ddim', 'eval_enc_dec_only': False, 'num_inf_videos_per_prompt': 1, 'num_inference_steps': 50, 'guidance_scale': 3.0, 'stepwise_sample_depth': -1, 'interpolation': None, 'interpolate_mode': None, 'visu_save': False, 'freeze_pose': False, 'freeze_background': False, 'ft_img_num': 0, 'ft_one_ref_image': True, 'ft_iters': None, 's1': 1.0, 's2': 1.0, 'ft_idx': None, 'ref_mode': 'first', '__module__': 'mymodule', 'task_name': 'ref_attn_clip_combine_controlnet', 'method_name': 'app_demo_image_edit', 'dataset_cf': 'dataset/app_demo_human_image_edit_singleinput.py', 'img_full_size': [256, 256], 'fps': 5, 'data_dir': './blob_dir/data/mtp_vlp_ray/debug/debug_pretrain', 'debug_train_yaml': './blob_dir/data/mtp_vlp_ray/debug/debug_pretrain/composite/train_webvid2.5m_2.yaml', 'debug_val_yaml': './blob_dir/data/mtp_vlp_ray/debug/debug_pretrain/composite/val_webvid2.5m.yaml', 'web_data_root': '/datadrive_d/wangtan/azure_storage/vigstandard_data/linjli/debug_output/video_sythesis/dataset/Lindsey_0504_youtube/frames/single_person', 'sd15_path': '/content/run_test/diffusers/stable-diffusion-v1-5-2', 'freeze_unet': True, 'num_inf_images_per_prompt': 1, '__doc__': None, 'n_gpu': 1, 'local_size': 1, 'num_gpus': 1, 'distributed': True, 'num_nodes': 1, 'word_size': 1, 'local_rank': 0, 'rank': 0, 'node_id': 0, 'dist': True, 'nodes': 1, 'world_size': 1, 'train_batch_size': 32, 'eval_batch_size': 32}\n"
          ]
        }
=======
>>>>>>> d4049c1 (gitignore)
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
>>>>>>> 03730c0 (new changes)
      "source": [
        "logger.warning(\"Do eval_visu...\")\n",
        "if getattr(args, 'refer_clip_preprocess', None):\n",
        "    eval_dataset = BaseDataset(args, args.val_yaml, split='val', preprocesser=model.feature_extractor)\n",
        "else:\n",
        "    eval_dataset = BaseDataset(args, args.val_yaml, split='val')\n",
        "eval_dataloader, eval_info = make_data_loader(\n",
        "    args, args.local_eval_batch_size,\n",
        "    eval_dataset)\n",
        "\n",
        "\n",
        "trainer = Agent_LDM(args=args, model=model)\n",
        "trainer.eval_demo_pre()"
<<<<<<< HEAD
=======
      ],
=======
      "execution_count": null,
>>>>>>> d4049c1 (gitignore)
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmhxcD304rY-",
        "outputId": "6bf849a9-384b-483d-efca-e6438377ac6d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[33m[2023-07-09 00:00:49 <<ipython-input-4-a21f1cb1709e>:3> <cell line: 3>] Do eval_visu...\u001b[0m\n",
            "\u001b[33m[2023-07-09 00:00:49 <<ipython-input-4-a21f1cb1709e>:3> <cell line: 3>] Do eval_visu...\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of samples: 25\n",
            "Specify the load model path, not use deepspeed but the pytorch original load func\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2023-07-09 00:01:11 <wutils_ldm.py:456> file2data] Loaded data from /content/mp_rank_00_model_states.pt\u001b[0m\n",
            "[2023-07-09 00:01:11 <wutils_ldm.py:456> file2data] Loaded data from /content/mp_rank_00_model_states.pt\u001b[0m\n",
            "\u001b[33m[2023-07-09 00:01:15 <wutils_ldm.py:701> adaptively_load_state_dict] Strictly Loaded state_dict.\u001b[0m\n",
            "\u001b[33m[2023-07-09 00:01:15 <wutils_ldm.py:701> adaptively_load_state_dict] Strictly Loaded state_dict.\u001b[0m\n",
            "\u001b[33m[2023-07-09 00:01:15 <agent.py:808> load_checkpoint_for_deepspeed_diff_gpu] Loaded checkpoint /content/mp_rank_00_model_states.pt of global_step 7200\u001b[0m\n",
            "\u001b[33m[2023-07-09 00:01:15 <agent.py:808> load_checkpoint_for_deepspeed_diff_gpu] Loaded checkpoint /content/mp_rank_00_model_states.pt of global_step 7200\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-07-09 00:01:16,138] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed info: version=0.6.3, git-hash=unknown, git-branch=unknown\n",
            "[2023-07-09 00:01:16,445] [INFO] [engine.py:278:__init__] DeepSpeed Flops Profiler Enabled: False\n",
            "[2023-07-09 00:01:16,455] [INFO] [config.py:1059:print] DeepSpeedEngine configuration:\n",
            "[2023-07-09 00:01:16,458] [INFO] [config.py:1063:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2023-07-09 00:01:16,460] [INFO] [config.py:1063:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2023-07-09 00:01:16,462] [INFO] [config.py:1063:print]   amp_enabled .................. False\n",
            "[2023-07-09 00:01:16,464] [INFO] [config.py:1063:print]   amp_params ................... False\n",
            "[2023-07-09 00:01:16,467] [INFO] [config.py:1063:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": null, \n",
            "    \"exps_dir\": null, \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2023-07-09 00:01:16,468] [INFO] [config.py:1063:print]   bfloat16_enabled ............. False\n",
            "[2023-07-09 00:01:16,469] [INFO] [config.py:1063:print]   checkpoint_tag_validation_enabled  True\n",
            "[2023-07-09 00:01:16,470] [INFO] [config.py:1063:print]   checkpoint_tag_validation_fail  False\n",
            "[2023-07-09 00:01:16,472] [INFO] [config.py:1063:print]   communication_data_type ...... None\n",
            "[2023-07-09 00:01:16,473] [INFO] [config.py:1063:print]   curriculum_enabled ........... False\n",
            "[2023-07-09 00:01:16,474] [INFO] [config.py:1063:print]   curriculum_params ............ False\n",
            "[2023-07-09 00:01:16,475] [INFO] [config.py:1063:print]   dataloader_drop_last ......... False\n",
            "[2023-07-09 00:01:16,476] [INFO] [config.py:1063:print]   disable_allgather ............ False\n",
            "[2023-07-09 00:01:16,477] [INFO] [config.py:1063:print]   dump_state ................... False\n",
            "[2023-07-09 00:01:16,478] [INFO] [config.py:1063:print]   dynamic_loss_scale_args ...... None\n",
            "[2023-07-09 00:01:16,479] [INFO] [config.py:1063:print]   eigenvalue_enabled ........... False\n",
            "[2023-07-09 00:01:16,479] [INFO] [config.py:1063:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2023-07-09 00:01:16,480] [INFO] [config.py:1063:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2023-07-09 00:01:16,481] [INFO] [config.py:1063:print]   eigenvalue_layer_num ......... 0\n",
            "[2023-07-09 00:01:16,482] [INFO] [config.py:1063:print]   eigenvalue_max_iter .......... 100\n",
            "[2023-07-09 00:01:16,483] [INFO] [config.py:1063:print]   eigenvalue_stability ......... 1e-06\n",
            "[2023-07-09 00:01:16,484] [INFO] [config.py:1063:print]   eigenvalue_tol ............... 0.01\n",
            "[2023-07-09 00:01:16,485] [INFO] [config.py:1063:print]   eigenvalue_verbose ........... False\n",
            "[2023-07-09 00:01:16,486] [INFO] [config.py:1063:print]   elasticity_enabled ........... False\n",
            "[2023-07-09 00:01:16,487] [INFO] [config.py:1063:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 3, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2023-07-09 00:01:16,488] [INFO] [config.py:1063:print]   fp16_enabled ................. True\n",
            "[2023-07-09 00:01:16,489] [INFO] [config.py:1063:print]   fp16_master_weights_and_gradients  False\n",
            "[2023-07-09 00:01:16,490] [INFO] [config.py:1063:print]   fp16_mixed_quantize .......... False\n",
            "[2023-07-09 00:01:16,491] [INFO] [config.py:1063:print]   global_rank .................. 0\n",
            "[2023-07-09 00:01:16,492] [INFO] [config.py:1063:print]   gradient_accumulation_steps .. 1\n",
            "[2023-07-09 00:01:16,493] [INFO] [config.py:1063:print]   gradient_clipping ............ 0.0\n",
            "[2023-07-09 00:01:16,494] [INFO] [config.py:1063:print]   gradient_predivide_factor .... 1.0\n",
            "[2023-07-09 00:01:16,494] [INFO] [config.py:1063:print]   initial_dynamic_scale ........ 4294967296\n",
            "[2023-07-09 00:01:16,496] [INFO] [config.py:1063:print]   loss_scale ................... 0\n",
            "[2023-07-09 00:01:16,497] [INFO] [config.py:1063:print]   memory_breakdown ............. False\n",
            "[2023-07-09 00:01:16,498] [INFO] [config.py:1063:print]   optimizer_legacy_fusion ...... False\n",
            "[2023-07-09 00:01:16,499] [INFO] [config.py:1063:print]   optimizer_name ............... None\n",
            "[2023-07-09 00:01:16,500] [INFO] [config.py:1063:print]   optimizer_params ............. None\n",
            "[2023-07-09 00:01:16,501] [INFO] [config.py:1063:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
            "[2023-07-09 00:01:16,502] [INFO] [config.py:1063:print]   pld_enabled .................. False\n",
            "[2023-07-09 00:01:16,502] [INFO] [config.py:1063:print]   pld_params ................... False\n",
            "[2023-07-09 00:01:16,503] [INFO] [config.py:1063:print]   prescale_gradients ........... False\n",
            "[2023-07-09 00:01:16,504] [INFO] [config.py:1063:print]   quantize_change_rate ......... 0.001\n",
            "[2023-07-09 00:01:16,506] [INFO] [config.py:1063:print]   quantize_groups .............. 1\n",
            "[2023-07-09 00:01:16,507] [INFO] [config.py:1063:print]   quantize_offset .............. 1000\n",
            "[2023-07-09 00:01:16,508] [INFO] [config.py:1063:print]   quantize_period .............. 1000\n",
            "[2023-07-09 00:01:16,509] [INFO] [config.py:1063:print]   quantize_rounding ............ 0\n",
            "[2023-07-09 00:01:16,510] [INFO] [config.py:1063:print]   quantize_start_bits .......... 16\n",
            "[2023-07-09 00:01:16,511] [INFO] [config.py:1063:print]   quantize_target_bits ......... 8\n",
            "[2023-07-09 00:01:16,512] [INFO] [config.py:1063:print]   quantize_training_enabled .... False\n",
            "[2023-07-09 00:01:16,513] [INFO] [config.py:1063:print]   quantize_type ................ 0\n",
            "[2023-07-09 00:01:16,514] [INFO] [config.py:1063:print]   quantize_verbose ............. False\n",
            "[2023-07-09 00:01:16,515] [INFO] [config.py:1063:print]   scheduler_name ............... None\n",
            "[2023-07-09 00:01:16,516] [INFO] [config.py:1063:print]   scheduler_params ............. None\n",
            "[2023-07-09 00:01:16,517] [INFO] [config.py:1063:print]   sparse_attention ............. None\n",
            "[2023-07-09 00:01:16,518] [INFO] [config.py:1063:print]   sparse_gradients_enabled ..... False\n",
            "[2023-07-09 00:01:16,519] [INFO] [config.py:1063:print]   steps_per_print .............. 10\n",
            "[2023-07-09 00:01:16,520] [INFO] [config.py:1063:print]   tensorboard_enabled .......... True\n",
            "[2023-07-09 00:01:16,521] [INFO] [config.py:1063:print]   tensorboard_job_name ......... tensorboard_log\n",
            "[2023-07-09 00:01:16,522] [INFO] [config.py:1063:print]   tensorboard_output_path ...... /content/run_test/exp/tiktok_ft\n",
            "[2023-07-09 00:01:16,523] [INFO] [config.py:1063:print]   train_batch_size ............. 32\n",
            "[2023-07-09 00:01:16,524] [INFO] [config.py:1063:print]   train_micro_batch_size_per_gpu  32\n",
            "[2023-07-09 00:01:16,525] [INFO] [config.py:1063:print]   use_quantizer_kernel ......... False\n",
            "[2023-07-09 00:01:16,526] [INFO] [config.py:1063:print]   wall_clock_breakdown ......... False\n",
            "[2023-07-09 00:01:16,527] [INFO] [config.py:1063:print]   world_size ................... 1\n",
            "[2023-07-09 00:01:16,528] [INFO] [config.py:1063:print]   zero_allow_untested_optimizer  False\n",
            "[2023-07-09 00:01:16,529] [INFO] [config.py:1063:print]   zero_config .................. {\n",
            "    \"stage\": 0, \n",
            "    \"contiguous_gradients\": true, \n",
            "    \"reduce_scatter\": true, \n",
            "    \"reduce_bucket_size\": 5.000000e+08, \n",
            "    \"allgather_partitions\": true, \n",
            "    \"allgather_bucket_size\": 5.000000e+08, \n",
            "    \"overlap_comm\": false, \n",
            "    \"load_from_fp32_weights\": true, \n",
            "    \"elastic_checkpoint\": false, \n",
            "    \"offload_param\": null, \n",
            "    \"offload_optimizer\": null, \n",
            "    \"sub_group_size\": 1.000000e+09, \n",
            "    \"prefetch_bucket_size\": 5.000000e+07, \n",
            "    \"param_persistence_threshold\": 1.000000e+05, \n",
            "    \"max_live_parameters\": 1.000000e+09, \n",
            "    \"max_reuse_distance\": 1.000000e+09, \n",
            "    \"gather_16bit_weights_on_model_save\": false, \n",
            "    \"ignore_unused_parameters\": true, \n",
            "    \"round_robin_gradients\": false, \n",
            "    \"legacy_stage1\": false\n",
            "}\n",
            "[2023-07-09 00:01:16,530] [INFO] [config.py:1063:print]   zero_enabled ................. False\n",
            "[2023-07-09 00:01:16,531] [INFO] [config.py:1063:print]   zero_optimization_stage ...... 0\n",
            "[2023-07-09 00:01:16,533] [INFO] [config.py:1065:print]   json = {\n",
            "    \"train_micro_batch_size_per_gpu\": 32, \n",
            "    \"gradient_accumulation_steps\": 1, \n",
            "    \"fp16\": {\n",
            "        \"enabled\": true\n",
            "    }, \n",
            "    \"flops_profiler\": {\n",
            "        \"enabled\": false, \n",
            "        \"profile_step\": 1, \n",
            "        \"module_depth\": -1, \n",
            "        \"top_modules\": 3, \n",
            "        \"detailed\": true\n",
            "    }, \n",
            "    \"tensorboard\": {\n",
            "        \"enabled\": true, \n",
            "        \"output_path\": \"/content/run_test/exp/tiktok_ft\", \n",
            "        \"job_name\": \"tensorboard_log\"\n",
            "    }\n",
            "}\n",
            "Using /root/.cache/torch_extensions/py310_cu113 as PyTorch extensions root...\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu113/utils/build.ninja...\n",
            "Building extension module utils...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.19990110397338867 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2023-07-09 00:01:18 <agent.py:237> prepare_dist_model] Successfully built models with {'trainable': 1581790996, 'frozen': 387620071, 'trainable_fp32': 0, 'trainalbe_fp16': 1581790996, 'frozen_fp32': 303966208, 'frozen_fp16': 83653863} parameters\u001b[0m\n",
            "[2023-07-09 00:01:18 <agent.py:237> prepare_dist_model] Successfully built models with {'trainable': 1581790996, 'frozen': 387620071, 'trainable_fp32': 0, 'trainalbe_fp16': 1581790996, 'frozen_fp32': 303966208, 'frozen_fp16': 83653863} parameters\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mode [all]: There are 686 modules in unet to be set as requires_grad=True.\n"
          ]
        }
<<<<<<< HEAD
>>>>>>> 03730c0 (new changes)
=======
      ],
      "source": [
        "logger.warning(\"Do eval_visu...\")\n",
        "if getattr(args, 'refer_clip_preprocess', None):\n",
        "    eval_dataset = BaseDataset(args, args.val_yaml, split='val', preprocesser=model.feature_extractor)\n",
        "else:\n",
        "    eval_dataset = BaseDataset(args, args.val_yaml, split='val')\n",
        "eval_dataloader, eval_info = make_data_loader(\n",
        "    args, args.local_eval_batch_size,\n",
        "    eval_dataset)\n",
        "\n",
        "\n",
        "trainer = Agent_LDM(args=args, model=model)\n",
        "trainer.eval_demo_pre()"
>>>>>>> d4049c1 (gitignore)
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> d4049c1 (gitignore)
      "execution_count": null,
      "metadata": {
        "id": "fF-xqrj95ekN"
      },
      "outputs": [],
<<<<<<< HEAD
=======
>>>>>>> 03730c0 (new changes)
=======
>>>>>>> d4049c1 (gitignore)
      "source": [
        "def load_image(image):\n",
        "    if not image.mode == \"RGB\":\n",
        "        image = image.convert(\"RGB\")\n",
        "    return image\n",
        "\n",
        "@torch.no_grad()\n",
        "def inference(reference_fg, fg_mask, ref_bg_image, bg_mask, skeleton_img, *args, **kwargs):\n",
        "    reference_fg = load_image(reference_fg)\n",
        "    fg_mask = load_image(fg_mask)\n",
        "    ref_bg_image = load_image(ref_bg_image)\n",
        "    bg_mask = load_image(bg_mask)\n",
        "    skeleton_img = load_image(skeleton_img)\n",
        "\n",
        "    input_data = [reference_fg, fg_mask, ref_bg_image, bg_mask, skeleton_img]\n",
        "    output_image = trainer.eval_demo_run(input_data, eval_dataset=eval_dataset)\n",
        "    return output_image\n",
        "\n",
        "@torch.no_grad()\n",
        "def inference_masked(reference_fg, ref_bg_image, skeleton_img, *args, **kwargs):\n",
        "    reference_fg = load_image(reference_fg)\n",
        "    ref_bg_image = load_image(ref_bg_image)\n",
        "    skeleton_img = load_image(skeleton_img)\n",
        "\n",
        "    input_data = [reference_fg, ref_bg_image, skeleton_img]\n",
        "    output_image = trainer.eval_demo_run_masked(input_data, eval_dataset=eval_dataset)\n",
        "    return output_image"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv2ZhLq_77Ik"
      },
      "source": [
        "### 5. Launch the gradio demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "yvs61CCg5iZV",
        "outputId": "a695e4b9-bc67-49c5-fb9d-9983648fd2ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-11e6eef69ecf>:31: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
            "  with gr.Row().style(equal_height=False):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://e249d08ffc1f80b5e5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://e249d08ffc1f80b5e5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
=======
      ],
      "metadata": {
        "id": "fF-xqrj95ekN"
      },
      "execution_count": null,
      "outputs": []
=======
      ]
>>>>>>> d4049c1 (gitignore)
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv2ZhLq_77Ik"
      },
      "source": [
        "### 5. Launch the gradio demo"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
>>>>>>> 03730c0 (new changes)
=======
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "yvs61CCg5iZV",
        "outputId": "a695e4b9-bc67-49c5-fb9d-9983648fd2ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-11e6eef69ecf>:31: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
            "  with gr.Row().style(equal_height=False):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://e249d08ffc1f80b5e5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://e249d08ffc1f80b5e5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
>>>>>>> d4049c1 (gitignore)
      "source": [
        "\n",
        "\n",
        "import gradio as gr\n",
        "'''\n",
        "launch app\n",
        "'''\n",
        "title = \"DisCo Demo (Video Demo Comming Soon!)\"\n",
        "description = \"\"\"<p style='text-align: center'> <a href='https://disco-dance.github.io/' target='_blank'>Project Page</a> | <a href='https://arxiv.org/pdf/2212.11270.pdf' target='_blank'>Paper</a> | <a href='https://github.com/microsoft/X-Decoder' target='_blank'>Github Repo</a> | <a href='https://youtu.be/wYp6vmyolqE' target='_blank'>Video</a> </p>\n",
        "<p>Skip the queue by duplicating this space and upgrading to GPU in settings</p>\n",
        "<a href=\"https://huggingface.co/spaces/xdecoder/Demo?duplicate=true\"><img src=\"https://bit.ly/3gLdBN6\" alt=\"Duplicate Space\"></a>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    # DisCo Demo (Video Demo Comming Soon!)\n",
        "    Start edit the human with provided human foreground, background, pose.\n",
        "\n",
        "    Note that for self-uploaded images, TikTok-Style human images are preferred.\n",
        "\n",
        "    [Project Page](https://disco-dance.github.io/) | [Github](https://github.com/Wangt-CN/DisCo)\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row().style(equal_height=False):\n",
        "        with gr.Column(min_width=400, scale=2):\n",
        "            input_fg = gr.Image(type='pil',label=\"Foreground Image\")\n",
        "            gr.Examples(examples=[\"./demo_data/fg/masked_images/00035.png\", \"./demo_data/fg/masked_images/00335.png\", \"./demo_data/fg/masked_images/00147.png\", \"./demo_data/fg/masked_images/00072.png\", \"./demo_data/fg/masked_images/00115.png\"], inputs=input_fg)\n",
        "\n",
        "            input_bg = gr.Image(type='pil',label=\"Background Image\")\n",
        "            gr.Examples(examples=[\"./demo_data/bg/masked_images/00035.png\", \"./demo_data/bg/masked_images/00335.png\", \"./demo_data/bg/masked_images/00147.png\", \"./demo_data/bg/masked_images/00072.png\", \"./demo_data/bg/masked_images/00115.png\"], inputs=input_bg)\n",
        "\n",
        "            input_pose = gr.Image(type='pil',label=\"Target Pose\",scale=1)\n",
        "            gr.Examples(examples=[\"./demo_data/pose_img/0049.png\",\"./demo_data/pose_img/0198.png\",\"./demo_data/pose_img/0213.png\",\"./demo_data/pose_img/0264.png\",\"./demo_data/pose_img/0144.png\",\"./demo_data/pose_img/0054.png\"], inputs=input_pose)\n",
        "\n",
        "            btn = gr.Button(\"Generate\")\n",
        "\n",
        "\n",
        "        with gr.Column(min_width=150):\n",
        "            output_img = gr.Image(type='pil',label=\"Edited Human Image\")\n",
        "\n",
        "    btn.click(inference_masked, inputs=[input_fg, input_bg, input_pose], outputs=[output_img])\n",
        "\n",
        "demo.queue(concurrency_count=2)\n",
        "demo.launch(share=True)"
<<<<<<< HEAD
<<<<<<< HEAD
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
=======
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "yvs61CCg5iZV",
        "outputId": "a695e4b9-bc67-49c5-fb9d-9983648fd2ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-11e6eef69ecf>:31: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
            "  with gr.Row().style(equal_height=False):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://e249d08ffc1f80b5e5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e249d08ffc1f80b5e5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}
>>>>>>> 03730c0 (new changes)
=======
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
>>>>>>> d4049c1 (gitignore)
