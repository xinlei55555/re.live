{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qu-pX4GDlgs",
        "outputId": "44ff79d4-a19c-4edb-adec-d1436b82035b"
      },
      "outputs": [],
      "source": [
        "# !nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7Som16t69XO"
      },
      "source": [
        "### 1. Clone the github repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKByNFtrfV7M",
        "outputId": "e5b86d37-badb-4aa6-adb3-3719b14d9c05"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/Wangt-CN/DisCo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpXDRYzO6rEY"
      },
      "source": [
        "\n",
        "### 2. Install the package\n",
        "\n",
        "Ps: Most errors are due to the unsuccessful package installation, please check the installation carefully.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "37UDwQVxfp4T"
      },
      "outputs": [],
      "source": [
        "# !pip install --user torch==1.12.1+cu113 torchvision==0.13.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# !pip install --user progressbar psutil pymongo simplejson yacs boto3 pyyaml ete3 easydict deprecated future django orderedset python-magic datasets h5py omegaconf einops ipdb\n",
        "# !pip install --user --exists-action w -r DisCo/requirements.txt\n",
        "# !pip install git+https://github.com/microsoft/azfuse.git\n",
        "\n",
        "# # for acceleration\n",
        "# !pip install --user deepspeed==0.6.3\n",
        "# !pip install -v -U git+https://github.com/facebookresearch/xformers.git@main#egg=xformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkfPye5C7FDV"
      },
      "source": [
        "### 3. Download the pretrained model\n",
        "Feel free to use our other [checkpoints](https://github.com/Wangt-CN/DisCo#model-checkpoint-google-cloud-tiktok-training-data-fid-fvd-188--more-tiktok-style-training-data-fid-fvd-157) or change to your own model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5FjMXqkh827",
        "outputId": "22add15e-c6a2-4993-fd41-e22f2467b036"
      },
      "outputs": [],
      "source": [
        "# !git clone https://huggingface.co/lambdalabs/sd-image-variations-diffusers\n",
        "# !wget https://storage.googleapis.com/disco-checkpoint-share/checkpoint_ft/moretiktok_nocfg/mp_rank_00_model_states.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-u3ohQt7o2c"
      },
      "source": [
        "### 4. Start Running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "n2knZKbPsxsj",
        "outputId": "55ca73c3-3e44-49af-eb98-8e339e31c4b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/DisCo'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.chdir('/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/DisCo/')\n",
        "#when running this, you have to put the right folder.\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "513HsIP_sHMW",
        "outputId": "11ad32f5-c377-481b-b41f-89637d60ac3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/DisCo\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "os.environ[\"WANDB_ENABLE\"] = \"0\"\n",
        "\n",
        "# going into this file and importing everything\n",
        "from DisCo.utils.wutils_ldm import *\n",
        "\n",
        "from DisCo.agent import Agent_LDM, WarmupLinearLR, WarmupLinearConstantLR\n",
        "import torch\n",
        "from DisCo.config.basicargs import BasicArgs #i modifified thid \n",
        "from DisCo.utils.lib import *\n",
        "from DisCo.utils.args import parse_with_cf\n",
        "from DisCo.utils.dist import dist_init\n",
        "from DisCo.dataset.tsv_dataset import make_data_sampler, make_batch_data_sampler\n",
        "from DisCo.finetune_sdm_yaml import get_loader_info, make_data_loader\n",
        "torch.multiprocessing.set_sharing_strategy('file_system')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCuG7qZ3zjYi",
        "outputId": "30b7e8cc-b12a-45fa-c050-3e285fa828bc"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'config.ref_attn_clip_combine_controlnet'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[29], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfig filename \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m args\u001b[38;5;241m.\u001b[39mcf)\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args\n\u001b[0;32m---> 40\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[43mparse_with_cf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m args\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count() \u001b[38;5;66;03m# local size\u001b[39;00m\n\u001b[1;32m     43\u001b[0m args\u001b[38;5;241m.\u001b[39mlocal_size \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mn_gpu\n",
            "Cell \u001b[0;32mIn[29], line 28\u001b[0m, in \u001b[0;36mparse_with_cf\u001b[0;34m(parsed_args)\u001b[0m\n\u001b[1;32m     26\u001b[0m args \u001b[38;5;241m=\u001b[39m edict(\u001b[38;5;28mvars\u001b[39m(parsed_args))\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(parsed_args\u001b[38;5;241m.\u001b[39mcf):\n\u001b[0;32m---> 28\u001b[0m     cf \u001b[38;5;241m=\u001b[39m \u001b[43mimport_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     config_args \u001b[38;5;241m=\u001b[39m edict(\u001b[38;5;28mvars\u001b[39m(cf\u001b[38;5;241m.\u001b[39mArgs))\n\u001b[1;32m     30\u001b[0m     override_keys \u001b[38;5;241m=\u001b[39m {arg[\u001b[38;5;241m2\u001b[39m:]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m manual_args\n\u001b[1;32m     31\u001b[0m                      \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m)}\n",
            "File \u001b[0;32m/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/DisCo/utils/wutils_ldm.py:627\u001b[0m, in \u001b[0;36mimport_filename\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    625\u001b[0m module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mmodule_from_spec(spec)\n\u001b[1;32m    626\u001b[0m sys\u001b[38;5;241m.\u001b[39mmodules[spec\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m module\n\u001b[0;32m--> 627\u001b[0m \u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexec_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\n",
            "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "File \u001b[0;32m/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/DisCo/config/ref_attn_clip_combine_controlnet/app_demo_image_edit.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mref_attn_clip_combine_controlnet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Net, inner_collect_fn\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mArgs\u001b[39;00m(BasicArgs):\n\u001b[1;32m      7\u001b[0m     task_name, method_name \u001b[38;5;241m=\u001b[39m BasicArgs\u001b[38;5;241m.\u001b[39mparse_config_name(\u001b[38;5;18m__file__\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'config.ref_attn_clip_combine_controlnet'"
          ]
        }
      ],
      "source": [
        "from DisCo.utils.args import sharedArgs\n",
        "manual_args = ['--cf', \n",
        "'/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/DisCo/config/ref_attn_clip_combine_controlnet/app_demo_image_edit.py', \n",
        "'--eval_visu', 'True', '--root_dir', '/content/run_test', '--local_train_batch_size', '32', '--local_eval_batch_size', '32', '--log_dir', 'exp/tiktok_ft', '--epochs', '20', '--deepspeed', '--eval_step', '500',\n",
        "               '--save_step', '500', '--gradient_accumulate_steps', '1', '--learning_rate', '2e-4', '--fix_dist_seed', 'True', '--loss_target',\n",
        "               'noise', '--unet_unfreeze_type', 'all', '--guidance_scale', '3', '--refer_sdvae', 'True', '--ref_null_caption', 'False', '--combine_clip_local', 'True', '--combine_use_mask', 'True', '--conds', 'poses','masks', 'model_pretrained.pt', '/content/mp_rank_00_model_states.pt', '/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/pretrained-image-model/model_pretrained.pt', '/content/sd-image-variations-diffusers', '--eval_save_filename', 'try']\n",
        "parsed_args = sharedArgs.parser.parse_args(args=manual_args)\n",
        "\n",
        "###### process the args #######\n",
        "if parsed_args.root_dir:\n",
        "    BasicArgs.root_dir = parsed_args.root_dir\n",
        "else:\n",
        "    parsed_args.root_dir = BasicArgs.root_dir\n",
        "parsed_args.pretrained_model_path = r\"/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/pretrained-image-model/model_pretrained.pt\"\n",
        "#  os.path.join(parsed_args.root_dir, parsed_args.pretrained_model_path)\n",
        "\n",
        "def parse_with_cf(parsed_args):\n",
        "    \"\"\"This function will set args based on the input config file.\n",
        "    (1) it only overwrites unset parameters,\n",
        "        i.e., these parameters not set from user command line input\n",
        "    (2) it also sets configs in the config file but declared in the parser\n",
        "    \"\"\"\n",
        "    # convert to EasyDict object,\n",
        "    # enabling access from attributes even for nested config\n",
        "    # e.g., args.train_datasets[0].name\n",
        "    args = edict(vars(parsed_args))\n",
        "    if os.path.exists(parsed_args.cf):\n",
        "        cf = import_filename(parsed_args.cf)\n",
        "        config_args = edict(vars(cf.Args))\n",
        "        override_keys = {arg[2:].split(\"=\")[0] for arg in manual_args\n",
        "                         if arg.startswith(\"--\")}\n",
        "        # import pdb;pdb.set_trace()\n",
        "        for k, v in config_args.items():\n",
        "            if k not in override_keys:\n",
        "                setattr(args, k, v)\n",
        "    else:\n",
        "        raise NotImplementedError('Config filename %s does not exist.' % args.cf)\n",
        "    return args\n",
        "\n",
        "args = parse_with_cf(parsed_args)\n",
        "\n",
        "args.n_gpu = T.cuda.device_count() # local size\n",
        "args.local_size = args.n_gpu\n",
        "if args.root_dir not in args.log_dir:\n",
        "    args.log_dir = os.path.join(args.root_dir, args.log_dir)\n",
        "if args.stepwise_sample_depth == -1:\n",
        "    args.interpolation = None\n",
        "    args.interpolate_mode = None\n",
        "if args.interpolation != \"interpolate\":\n",
        "    args.interpolate_mode = None\n",
        "\n",
        "assert args.eval_step > 0, \"eval_step must be positive\"\n",
        "assert args.save_step > 0, \"save_step must be positive\"\n",
        "\n",
        "dist_init(args)\n",
        "args.dist = args.distributed\n",
        "args.nodes = args.num_nodes\n",
        "args.world_size = args.num_gpus\n",
        "args.train_batch_size = args.local_train_batch_size * args.world_size\n",
        "args.eval_batch_size = args.local_eval_batch_size * args.world_size\n",
        "#############################################\n",
        "\n",
        "cf = import_filename(args.cf)\n",
        "Net, inner_collect_fn = cf.Net, cf.inner_collect_fn\n",
        "\n",
        "dataset_cf = import_filename(args.dataset_cf)\n",
        "BaseDataset = dataset_cf.BaseDataset\n",
        "\n",
        "# args = update_args(parsed_args, args)\n",
        "\n",
        "# init models\n",
        "logger.info('Building models...')\n",
        "model = Net(args)\n",
        "print(f\"Args: {edict(vars(args))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmhxcD304rY-",
        "outputId": "6bf849a9-384b-483d-efca-e6438377ac6d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[33m[2024-01-26 23:52:19 <2716821498.py:1> <module>] Do eval_visu...\u001b[0m\n",
            "\u001b[33m[2024-01-26 23:52:19 <2716821498.py:1> <module>] Do eval_visu...\u001b[0m\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'args' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDo eval_visu...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43margs\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrefer_clip_preprocess\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      3\u001b[0m     eval_dataset \u001b[38;5;241m=\u001b[39m BaseDataset(args, args\u001b[38;5;241m.\u001b[39mval_yaml, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocesser\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfeature_extractor)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
          ]
        }
      ],
      "source": [
        "logger.warning(\"Do eval_visu...\")\n",
        "if getattr(args, 'refer_clip_preprocess', None):\n",
        "    eval_dataset = BaseDataset(args, args.val_yaml, split='val', preprocesser=model.feature_extractor)\n",
        "else:\n",
        "    eval_dataset = BaseDataset(args, args.val_yaml, split='val')\n",
        "eval_dataloader, eval_info = make_data_loader(\n",
        "    args, args.local_eval_batch_size,\n",
        "    eval_dataset)\n",
        "\n",
        "\n",
        "trainer = Agent_LDM(args=args, model=model)\n",
        "trainer.eval_demo_pre()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fF-xqrj95ekN"
      },
      "outputs": [],
      "source": [
        "def load_image(image):\n",
        "    if not image.mode == \"RGB\":\n",
        "        image = image.convert(\"RGB\")\n",
        "    return image\n",
        "\n",
        "@torch.no_grad()\n",
        "def inference(reference_fg, fg_mask, ref_bg_image, bg_mask, skeleton_img, *args, **kwargs):\n",
        "    reference_fg = load_image(reference_fg)\n",
        "    fg_mask = load_image(fg_mask)\n",
        "    ref_bg_image = load_image(ref_bg_image)\n",
        "    bg_mask = load_image(bg_mask)\n",
        "    skeleton_img = load_image(skeleton_img)\n",
        "\n",
        "    input_data = [reference_fg, fg_mask, ref_bg_image, bg_mask, skeleton_img]\n",
        "    output_image = trainer.eval_demo_run(input_data, eval_dataset=eval_dataset)\n",
        "    return output_image\n",
        "\n",
        "@torch.no_grad()\n",
        "def inference_masked(reference_fg, ref_bg_image, skeleton_img, *args, **kwargs):\n",
        "    reference_fg = load_image(reference_fg)\n",
        "    ref_bg_image = load_image(ref_bg_image)\n",
        "    skeleton_img = load_image(skeleton_img)\n",
        "\n",
        "    input_data = [reference_fg, ref_bg_image, skeleton_img]\n",
        "    output_image = trainer.eval_demo_run_masked(input_data, eval_dataset=eval_dataset)\n",
        "    return output_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv2ZhLq_77Ik"
      },
      "source": [
        "### 5. Launch the gradio demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "yvs61CCg5iZV",
        "outputId": "a695e4b9-bc67-49c5-fb9d-9983648fd2ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-11e6eef69ecf>:31: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
            "  with gr.Row().style(equal_height=False):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://e249d08ffc1f80b5e5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://e249d08ffc1f80b5e5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "import gradio as gr\n",
        "'''\n",
        "launch app\n",
        "'''\n",
        "title = \"DisCo Demo (Video Demo Comming Soon!)\"\n",
        "description = \"\"\"<p style='text-align: center'> <a href='https://disco-dance.github.io/' target='_blank'>Project Page</a> | <a href='https://arxiv.org/pdf/2212.11270.pdf' target='_blank'>Paper</a> | <a href='https://github.com/microsoft/X-Decoder' target='_blank'>Github Repo</a> | <a href='https://youtu.be/wYp6vmyolqE' target='_blank'>Video</a> </p>\n",
        "<p>Skip the queue by duplicating this space and upgrading to GPU in settings</p>\n",
        "<a href=\"https://huggingface.co/spaces/xdecoder/Demo?duplicate=true\"><img src=\"https://bit.ly/3gLdBN6\" alt=\"Duplicate Space\"></a>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    # DisCo Demo (Video Demo Comming Soon!)\n",
        "    Start edit the human with provided human foreground, background, pose.\n",
        "\n",
        "    Note that for self-uploaded images, TikTok-Style human images are preferred.\n",
        "\n",
        "    [Project Page](https://disco-dance.github.io/) | [Github](https://github.com/Wangt-CN/DisCo)\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row().style(equal_height=False):\n",
        "        with gr.Column(min_width=400, scale=2):\n",
        "            input_fg = gr.Image(type='pil',label=\"Foreground Image\")\n",
        "            gr.Examples(examples=[\"./demo_data/fg/masked_images/00035.png\", \"./demo_data/fg/masked_images/00335.png\", \"./demo_data/fg/masked_images/00147.png\", \"./demo_data/fg/masked_images/00072.png\", \"./demo_data/fg/masked_images/00115.png\"], inputs=input_fg)\n",
        "\n",
        "            input_bg = gr.Image(type='pil',label=\"Background Image\")\n",
        "            gr.Examples(examples=[\"./demo_data/bg/masked_images/00035.png\", \"./demo_data/bg/masked_images/00335.png\", \"./demo_data/bg/masked_images/00147.png\", \"./demo_data/bg/masked_images/00072.png\", \"./demo_data/bg/masked_images/00115.png\"], inputs=input_bg)\n",
        "\n",
        "            input_pose = gr.Image(type='pil',label=\"Target Pose\",scale=1)\n",
        "            gr.Examples(examples=[\"./demo_data/pose_img/0049.png\",\"./demo_data/pose_img/0198.png\",\"./demo_data/pose_img/0213.png\",\"./demo_data/pose_img/0264.png\",\"./demo_data/pose_img/0144.png\",\"./demo_data/pose_img/0054.png\"], inputs=input_pose)\n",
        "\n",
        "            btn = gr.Button(\"Generate\")\n",
        "\n",
        "\n",
        "        with gr.Column(min_width=150):\n",
        "            output_img = gr.Image(type='pil',label=\"Edited Human Image\")\n",
        "\n",
        "    btn.click(inference_masked, inputs=[input_fg, input_bg, input_pose], outputs=[output_img])\n",
        "\n",
        "demo.queue(concurrency_count=2)\n",
        "demo.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
