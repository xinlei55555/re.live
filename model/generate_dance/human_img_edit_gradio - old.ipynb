{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "473523df",
   "metadata": {},
   "source": [
    "### Example Jupyter Code for Generation Results with Gradio Demo\n",
    "\n",
    "```\n",
    "--------------------------------------------------------\n",
    "DisCo - Disentangled Control for Referring Human Dance Generation in Real World\n",
    "Licensed under The Apache-2.0 license License [see LICENSE for details]\n",
    "Tan Wang (TAN317@e.ntu.edu.sg)\n",
    "Work done during internship at Microsoft\n",
    "--------------------------------------------------------\n",
    "```\n",
    "\n",
    "Pls remember to change the path (model checkpoint, root dir, eval_save_filename, and so on) in the `manual_args`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdbf0c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/violet/Programs/miniconda3/envs/ai_hackathon2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[2024-01-27 01:05:21 <wutils_ldm.py:150> <module>] <utils.py>: Deep Learning Utils @ Chenfei Wu\u001b[0m\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils.lib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWANDB_ENABLE\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mDisCo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwutils_ldm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mDisCo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Agent_LDM, WarmupLinearLR, WarmupLinearConstantLR\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mDisCo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BasicArgs\n",
      "File \u001b[0;32m/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/DisCo/agent.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdist\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     is_main_process, get_world_size,\n\u001b[1;32m      4\u001b[0m     reduce_dict, get_local_rank, synchronize,\n\u001b[1;32m      5\u001b[0m     get_rank,)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetric_logger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m log_dict_to_wandb, setup_wandb, log_img_to_wandb\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils.lib'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"WANDB_ENABLE\"] = \"0\"\n",
    "\n",
    "from DisCo.utils.wutils_ldm import *\n",
    "from DisCo.agent import Agent_LDM, WarmupLinearLR, WarmupLinearConstantLR\n",
    "import torch\n",
    "from DisCo.config import BasicArgs\n",
    "from DisCo.utils.lib import *\n",
    "# from utils.args import parse_with_cf\n",
    "from DisCo.utils.dist import dist_init\n",
    "from DisCo.dataset.tsv_dataset import make_data_sampler, make_batch_data_sampler\n",
    "from DisCo.finetune_sdm_yaml import get_loader_info, make_data_loader\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8735d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fcd501",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config.ref_attn_clip_combine_controlnet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfig filename \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m args\u001b[38;5;241m.\u001b[39mcf)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args\n\u001b[0;32m---> 43\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[43mparse_with_cf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m args\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count() \u001b[38;5;66;03m# local size\u001b[39;00m\n\u001b[1;32m     46\u001b[0m args\u001b[38;5;241m.\u001b[39mlocal_size \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mn_gpu\n",
      "Cell \u001b[0;32mIn[22], line 31\u001b[0m, in \u001b[0;36mparse_with_cf\u001b[0;34m(parsed_args)\u001b[0m\n\u001b[1;32m     29\u001b[0m args \u001b[38;5;241m=\u001b[39m edict(\u001b[38;5;28mvars\u001b[39m(parsed_args))\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(parsed_args\u001b[38;5;241m.\u001b[39mcf):\n\u001b[0;32m---> 31\u001b[0m     cf \u001b[38;5;241m=\u001b[39m \u001b[43mimport_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     config_args \u001b[38;5;241m=\u001b[39m edict(\u001b[38;5;28mvars\u001b[39m(cf\u001b[38;5;241m.\u001b[39mArgs))\n\u001b[1;32m     33\u001b[0m     override_keys \u001b[38;5;241m=\u001b[39m {arg[\u001b[38;5;241m2\u001b[39m:]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m manual_args\n\u001b[1;32m     34\u001b[0m                      \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m)}\n",
      "File \u001b[0;32m/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/DisCo/utils/wutils_ldm.py:627\u001b[0m, in \u001b[0;36mimport_filename\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    625\u001b[0m module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mmodule_from_spec(spec)\n\u001b[1;32m    626\u001b[0m sys\u001b[38;5;241m.\u001b[39mmodules[spec\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m module\n\u001b[0;32m--> 627\u001b[0m \u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexec_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/DisCo/config/ref_attn_clip_combine_controlnet/app_demo_image_edit.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mref_attn_clip_combine_controlnet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Net, inner_collect_fn\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mArgs\u001b[39;00m(BasicArgs):\n\u001b[1;32m      7\u001b[0m     task_name, method_name \u001b[38;5;241m=\u001b[39m BasicArgs\u001b[38;5;241m.\u001b[39mparse_config_name(\u001b[38;5;18m__file__\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'config.ref_attn_clip_combine_controlnet'"
     ]
    }
   ],
   "source": [
    "from DisCo.utils.args import sharedArgs\n",
    "# manual_args = ['--cf', 'DisCo/config/ref_attn_clip_combine_controlnet/app_demo_image_edit.py', '--eval_visu', 'True', '--root_dir', '/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/DisCo/config', '--local_train_batch_size', '32', '--local_eval_batch_size', '32', '--log_dir', 'exp/tiktok_ft', '--epochs', '20', '--deepspeed', '--eval_step', '500',\n",
    "#                '--save_step', '500', '--gradient_accumulate_steps', '1', '--learning_rate', '2e-4', '--fix_dist_seed', 'True', '--loss_target',\n",
    "#                'noise', '--unet_unfreeze_type', 'all', '--guidance_scale', '3', '--refer_sdvae', 'True', '--ref_null_caption', 'False', '--combine_clip_local', 'True', '--combine_use_mask', 'True', '--conds', 'poses','masks', '--pretrained_model', '/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/pretrained-image-model/model_pretrained.pt', '--eval_save_filename', 'try']\n",
    "# parsed_args = sharedArgs.parser.parse_args(args=manual_args)\n",
    "manual_args = ['--cf', 'DisCo/config/ref_attn_clip_combine_controlnet/app_demo_image_edit.py', '--eval_visu', 'True', '--root_dir', '/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/DisCo/config/ref_attn_clip_combine_controlnet', '--local_train_batch_size', '32', '--local_eval_batch_size', '32', '--log_dir', 'exp/tiktok_ft', '--epochs', '20', '--deepspeed', '--eval_step', '500',\n",
    "               '--save_step', '500', '--gradient_accumulate_steps', '1', '--learning_rate', '2e-4', '--fix_dist_seed', 'True', '--loss_target',\n",
    "               'noise', '--unet_unfreeze_type', 'all', '--guidance_scale', '3', '--refer_sdvae', 'True', '--ref_null_caption', 'False', '--combine_clip_local', 'True', '--combine_use_mask', 'True', '--conds', 'poses','masks', '--pretrained_model', '/mnt/DATA/Personnel/Other learning/Programming/Personal_projects/3_Hackathons_with_buddies/uofthacks2024/model/generate_dance/pretrained-image-model/model_pretrained.pt', '--eval_save_filename', 'try']\n",
    "parsed_args = sharedArgs.parser.parse_args(args=manual_args)\n",
    "# args = sharedArgs.parser.parse_args(args=['--cf', 'config/ref_attn_clip_combine_controlnet/app_demo_image_edit.py', '--eval_visu', 'True'])\n",
    "# import pdb; pdb.set_trace()\n",
    "\n",
    "###### process the args #######\n",
    "if parsed_args.root_dir:\n",
    "    BasicArgs.root_dir = parsed_args.root_dir\n",
    "else:\n",
    "    parsed_args.root_dir = BasicArgs.root_dir\n",
    "parsed_args.pretrained_model_path = os.path.join(parsed_args.root_dir, parsed_args.pretrained_model_path)\n",
    "\n",
    "def parse_with_cf(parsed_args):\n",
    "    \"\"\"This function will set args based on the input config file.\n",
    "    (1) it only overwrites unset parameters,\n",
    "        i.e., these parameters not set from user command line input\n",
    "    (2) it also sets configs in the config file but declared in the parser\n",
    "    \"\"\"\n",
    "    # convert to EasyDict object,\n",
    "    # enabling access from attributes even for nested config\n",
    "    # e.g., args.train_datasets[0].name\n",
    "    args = edict(vars(parsed_args))\n",
    "    if os.path.exists(parsed_args.cf):\n",
    "        cf = import_filename(parsed_args.cf)\n",
    "        config_args = edict(vars(cf.Args))\n",
    "        override_keys = {arg[2:].split(\"=\")[0] for arg in manual_args\n",
    "                         if arg.startswith(\"--\")}\n",
    "        # import pdb;pdb.set_trace()\n",
    "        for k, v in config_args.items():\n",
    "            if k not in override_keys:\n",
    "                setattr(args, k, v)\n",
    "    else:\n",
    "        raise NotImplementedError('Config filename %s does not exist.' % args.cf)\n",
    "    return args\n",
    "\n",
    "args = parse_with_cf(parsed_args)\n",
    "        \n",
    "args.n_gpu = T.cuda.device_count() # local size\n",
    "args.local_size = args.n_gpu\n",
    "if args.root_dir not in args.log_dir:\n",
    "    args.log_dir = os.path.join(args.root_dir, args.log_dir)\n",
    "if args.stepwise_sample_depth == -1:\n",
    "    args.interpolation = None\n",
    "    args.interpolate_mode = None\n",
    "if args.interpolation != \"interpolate\":\n",
    "    args.interpolate_mode = None\n",
    "\n",
    "assert args.eval_step > 0, \"eval_step must be positive\"\n",
    "assert args.save_step > 0, \"save_step must be positive\"\n",
    "\n",
    "dist_init(args)\n",
    "args.dist = args.distributed\n",
    "args.nodes = args.num_nodes\n",
    "args.world_size = args.num_gpus\n",
    "args.train_batch_size = args.local_train_batch_size * args.world_size\n",
    "args.eval_batch_size = args.local_eval_batch_size * args.world_size\n",
    "#############################################\n",
    "\n",
    "cf = import_filename(args.cf)\n",
    "Net, inner_collect_fn = cf.Net, cf.inner_collect_fn\n",
    "\n",
    "dataset_cf = import_filename(args.dataset_cf)\n",
    "BaseDataset = dataset_cf.BaseDataset\n",
    "\n",
    "# args = update_args(parsed_args, args)\n",
    "\n",
    "# init models\n",
    "logger.info('Building models...')\n",
    "model = Net(args)\n",
    "print(f\"Args: {edict(vars(args))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019e44c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a550cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f876d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1666198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[2023-07-03 08:19:47 <287074974.py:3> <module>] Do eval_visu...\u001b[0m\n",
      "\u001b[33m[2023-07-03 08:19:47 <287074974.py:3> <module>] Do eval_visu...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 25\n",
      "Specify the load model path, not use deepspeed but the pytorch original load func\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-03 08:19:51 <wutils_ldm.py:456> file2data] Loaded data from /home/wangtan/data/disco/ft_checkpoint/moretiktok_nocfg/mp_rank_00_model_states.pt\u001b[0m\n",
      "[2023-07-03 08:19:51 <wutils_ldm.py:456> file2data] Loaded data from /home/wangtan/data/disco/ft_checkpoint/moretiktok_nocfg/mp_rank_00_model_states.pt\u001b[0m\n",
      "\u001b[33m[2023-07-03 08:19:54 <wutils_ldm.py:701> adaptively_load_state_dict] Strictly Loaded state_dict.\u001b[0m\n",
      "\u001b[33m[2023-07-03 08:19:54 <wutils_ldm.py:701> adaptively_load_state_dict] Strictly Loaded state_dict.\u001b[0m\n",
      "\u001b[33m[2023-07-03 08:19:54 <agent.py:808> load_checkpoint_for_deepspeed_diff_gpu] Loaded checkpoint /home/wangtan/data/disco/ft_checkpoint/moretiktok_nocfg/mp_rank_00_model_states.pt of global_step 7200\u001b[0m\n",
      "\u001b[33m[2023-07-03 08:19:54 <agent.py:808> load_checkpoint_for_deepspeed_diff_gpu] Loaded checkpoint /home/wangtan/data/disco/ft_checkpoint/moretiktok_nocfg/mp_rank_00_model_states.pt of global_step 7200\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-03 08:19:54,390] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed info: version=0.6.3, git-hash=unknown, git-branch=unknown\n",
      "[2023-07-03 08:19:54,729] [INFO] [engine.py:278:__init__] DeepSpeed Flops Profiler Enabled: False\n",
      "[2023-07-03 08:19:54,734] [INFO] [config.py:1059:print] DeepSpeedEngine configuration:\n",
      "[2023-07-03 08:19:54,736] [INFO] [config.py:1063:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-07-03 08:19:54,737] [INFO] [config.py:1063:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-07-03 08:19:54,738] [INFO] [config.py:1063:print]   amp_enabled .................. False\n",
      "[2023-07-03 08:19:54,739] [INFO] [config.py:1063:print]   amp_params ................... False\n",
      "[2023-07-03 08:19:54,740] [INFO] [config.py:1063:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": null, \n",
      "    \"exps_dir\": null, \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-07-03 08:19:54,740] [INFO] [config.py:1063:print]   bfloat16_enabled ............. False\n",
      "[2023-07-03 08:19:54,741] [INFO] [config.py:1063:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-07-03 08:19:54,742] [INFO] [config.py:1063:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-07-03 08:19:54,743] [INFO] [config.py:1063:print]   communication_data_type ...... None\n",
      "[2023-07-03 08:19:54,744] [INFO] [config.py:1063:print]   curriculum_enabled ........... False\n",
      "[2023-07-03 08:19:54,745] [INFO] [config.py:1063:print]   curriculum_params ............ False\n",
      "[2023-07-03 08:19:54,745] [INFO] [config.py:1063:print]   dataloader_drop_last ......... False\n",
      "[2023-07-03 08:19:54,746] [INFO] [config.py:1063:print]   disable_allgather ............ False\n",
      "[2023-07-03 08:19:54,747] [INFO] [config.py:1063:print]   dump_state ................... False\n",
      "[2023-07-03 08:19:54,748] [INFO] [config.py:1063:print]   dynamic_loss_scale_args ...... None\n",
      "[2023-07-03 08:19:54,748] [INFO] [config.py:1063:print]   eigenvalue_enabled ........... False\n",
      "[2023-07-03 08:19:54,749] [INFO] [config.py:1063:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-07-03 08:19:54,751] [INFO] [config.py:1063:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-07-03 08:19:54,752] [INFO] [config.py:1063:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-07-03 08:19:54,753] [INFO] [config.py:1063:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-07-03 08:19:54,753] [INFO] [config.py:1063:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-07-03 08:19:54,754] [INFO] [config.py:1063:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-07-03 08:19:54,755] [INFO] [config.py:1063:print]   eigenvalue_verbose ........... False\n",
      "[2023-07-03 08:19:54,755] [INFO] [config.py:1063:print]   elasticity_enabled ........... False\n",
      "[2023-07-03 08:19:54,756] [INFO] [config.py:1063:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 3, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-07-03 08:19:54,757] [INFO] [config.py:1063:print]   fp16_enabled ................. True\n",
      "[2023-07-03 08:19:54,757] [INFO] [config.py:1063:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-07-03 08:19:54,758] [INFO] [config.py:1063:print]   fp16_mixed_quantize .......... False\n",
      "[2023-07-03 08:19:54,758] [INFO] [config.py:1063:print]   global_rank .................. 0\n",
      "[2023-07-03 08:19:54,759] [INFO] [config.py:1063:print]   gradient_accumulation_steps .. 1\n",
      "[2023-07-03 08:19:54,760] [INFO] [config.py:1063:print]   gradient_clipping ............ 0.0\n",
      "[2023-07-03 08:19:54,760] [INFO] [config.py:1063:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-07-03 08:19:54,761] [INFO] [config.py:1063:print]   initial_dynamic_scale ........ 4294967296\n",
      "[2023-07-03 08:19:54,761] [INFO] [config.py:1063:print]   loss_scale ................... 0\n",
      "[2023-07-03 08:19:54,762] [INFO] [config.py:1063:print]   memory_breakdown ............. False\n",
      "[2023-07-03 08:19:54,763] [INFO] [config.py:1063:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-07-03 08:19:54,763] [INFO] [config.py:1063:print]   optimizer_name ............... None\n",
      "[2023-07-03 08:19:54,764] [INFO] [config.py:1063:print]   optimizer_params ............. None\n",
      "[2023-07-03 08:19:54,764] [INFO] [config.py:1063:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2023-07-03 08:19:54,765] [INFO] [config.py:1063:print]   pld_enabled .................. False\n",
      "[2023-07-03 08:19:54,765] [INFO] [config.py:1063:print]   pld_params ................... False\n",
      "[2023-07-03 08:19:54,766] [INFO] [config.py:1063:print]   prescale_gradients ........... False\n",
      "[2023-07-03 08:19:54,766] [INFO] [config.py:1063:print]   quantize_change_rate ......... 0.001\n",
      "[2023-07-03 08:19:54,767] [INFO] [config.py:1063:print]   quantize_groups .............. 1\n",
      "[2023-07-03 08:19:54,767] [INFO] [config.py:1063:print]   quantize_offset .............. 1000\n",
      "[2023-07-03 08:19:54,768] [INFO] [config.py:1063:print]   quantize_period .............. 1000\n",
      "[2023-07-03 08:19:54,768] [INFO] [config.py:1063:print]   quantize_rounding ............ 0\n",
      "[2023-07-03 08:19:54,769] [INFO] [config.py:1063:print]   quantize_start_bits .......... 16\n",
      "[2023-07-03 08:19:54,769] [INFO] [config.py:1063:print]   quantize_target_bits ......... 8\n",
      "[2023-07-03 08:19:54,770] [INFO] [config.py:1063:print]   quantize_training_enabled .... False\n",
      "[2023-07-03 08:19:54,770] [INFO] [config.py:1063:print]   quantize_type ................ 0\n",
      "[2023-07-03 08:19:54,771] [INFO] [config.py:1063:print]   quantize_verbose ............. False\n",
      "[2023-07-03 08:19:54,771] [INFO] [config.py:1063:print]   scheduler_name ............... None\n",
      "[2023-07-03 08:19:54,772] [INFO] [config.py:1063:print]   scheduler_params ............. None\n",
      "[2023-07-03 08:19:54,772] [INFO] [config.py:1063:print]   sparse_attention ............. None\n",
      "[2023-07-03 08:19:54,773] [INFO] [config.py:1063:print]   sparse_gradients_enabled ..... False\n",
      "[2023-07-03 08:19:54,773] [INFO] [config.py:1063:print]   steps_per_print .............. 10\n",
      "[2023-07-03 08:19:54,774] [INFO] [config.py:1063:print]   tensorboard_enabled .......... True\n",
      "[2023-07-03 08:19:54,774] [INFO] [config.py:1063:print]   tensorboard_job_name ......... tensorboard_log\n",
      "[2023-07-03 08:19:54,775] [INFO] [config.py:1063:print]   tensorboard_output_path ...... /home1/wangtan/code/ms_internship2/github_repo/run_test/exp/tiktok_ft\n",
      "[2023-07-03 08:19:54,775] [INFO] [config.py:1063:print]   train_batch_size ............. 32\n",
      "[2023-07-03 08:19:54,776] [INFO] [config.py:1063:print]   train_micro_batch_size_per_gpu  32\n",
      "[2023-07-03 08:19:54,776] [INFO] [config.py:1063:print]   use_quantizer_kernel ......... False\n",
      "[2023-07-03 08:19:54,776] [INFO] [config.py:1063:print]   wall_clock_breakdown ......... False\n",
      "[2023-07-03 08:19:54,777] [INFO] [config.py:1063:print]   world_size ................... 1\n",
      "[2023-07-03 08:19:54,777] [INFO] [config.py:1063:print]   zero_allow_untested_optimizer  False\n",
      "[2023-07-03 08:19:54,778] [INFO] [config.py:1063:print]   zero_config .................. {\n",
      "    \"stage\": 0, \n",
      "    \"contiguous_gradients\": true, \n",
      "    \"reduce_scatter\": true, \n",
      "    \"reduce_bucket_size\": 5.000000e+08, \n",
      "    \"allgather_partitions\": true, \n",
      "    \"allgather_bucket_size\": 5.000000e+08, \n",
      "    \"overlap_comm\": false, \n",
      "    \"load_from_fp32_weights\": true, \n",
      "    \"elastic_checkpoint\": false, \n",
      "    \"offload_param\": null, \n",
      "    \"offload_optimizer\": null, \n",
      "    \"sub_group_size\": 1.000000e+09, \n",
      "    \"prefetch_bucket_size\": 5.000000e+07, \n",
      "    \"param_persistence_threshold\": 1.000000e+05, \n",
      "    \"max_live_parameters\": 1.000000e+09, \n",
      "    \"max_reuse_distance\": 1.000000e+09, \n",
      "    \"gather_16bit_weights_on_model_save\": false, \n",
      "    \"ignore_unused_parameters\": true, \n",
      "    \"round_robin_gradients\": false, \n",
      "    \"legacy_stage1\": false\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-03 08:19:54,779] [INFO] [config.py:1063:print]   zero_enabled ................. False\n",
      "[2023-07-03 08:19:54,779] [INFO] [config.py:1063:print]   zero_optimization_stage ...... 0\n",
      "[2023-07-03 08:19:54,780] [INFO] [config.py:1065:print]   json = {\n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true\n",
      "    }, \n",
      "    \"flops_profiler\": {\n",
      "        \"enabled\": false, \n",
      "        \"profile_step\": 1, \n",
      "        \"module_depth\": -1, \n",
      "        \"top_modules\": 3, \n",
      "        \"detailed\": true\n",
      "    }, \n",
      "    \"tensorboard\": {\n",
      "        \"enabled\": true, \n",
      "        \"output_path\": \"/home1/wangtan/code/ms_internship2/github_repo/run_test/exp/tiktok_ft\", \n",
      "        \"job_name\": \"tensorboard_log\"\n",
      "    }\n",
      "}\n",
      "Using /home/wangtan/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/wangtan/.cache/torch_extensions/py38_cu113/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-03 08:19:56 <agent.py:237> prepare_dist_model] Successfully built models with {'trainable': 1581790996, 'frozen': 387620071, 'trainable_fp32': 0, 'trainalbe_fp16': 1581790996, 'frozen_fp32': 303966208, 'frozen_fp16': 83653863} parameters\u001b[0m\n",
      "[2023-07-03 08:19:56 <agent.py:237> prepare_dist_model] Successfully built models with {'trainable': 1581790996, 'frozen': 387620071, 'trainable_fp32': 0, 'trainalbe_fp16': 1581790996, 'frozen_fp32': 303966208, 'frozen_fp16': 83653863} parameters\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.8241767883300781 seconds\n",
      "Mode [all]: There are 686 modules in unet to be set as requires_grad=True.\n"
     ]
    }
   ],
   "source": [
    "### prepare the eval\n",
    "\n",
    "logger.warning(\"Do eval_visu...\")\n",
    "if getattr(args, 'refer_clip_preprocess', None):\n",
    "    eval_dataset = BaseDataset(args, args.val_yaml, split='val', preprocesser=model.feature_extractor)\n",
    "else:\n",
    "    eval_dataset = BaseDataset(args, args.val_yaml, split='val')\n",
    "eval_dataloader, eval_info = make_data_loader(\n",
    "    args, args.local_eval_batch_size, \n",
    "    eval_dataset)\n",
    "\n",
    "\n",
    "trainer = Agent_LDM(args=args, model=model)\n",
    "trainer.eval_demo_pre()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4377766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image):\n",
    "    if not image.mode == \"RGB\":\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def inference(reference_fg, fg_mask, ref_bg_image, bg_mask, skeleton_img, *args, **kwargs):\n",
    "    reference_fg = load_image(reference_fg)\n",
    "    fg_mask = load_image(fg_mask)\n",
    "    ref_bg_image = load_image(ref_bg_image)\n",
    "    bg_mask = load_image(bg_mask)\n",
    "    skeleton_img = load_image(skeleton_img)\n",
    "    \n",
    "    input_data = [reference_fg, fg_mask, ref_bg_image, bg_mask, skeleton_img]\n",
    "    output_image = trainer.eval_demo_run(input_data, eval_dataset=eval_dataset)\n",
    "    return output_image\n",
    "\n",
    "@torch.no_grad()\n",
    "def inference_masked(reference_fg, ref_bg_image, skeleton_img, *args, **kwargs):\n",
    "    reference_fg = load_image(reference_fg)\n",
    "    ref_bg_image = load_image(ref_bg_image)\n",
    "    skeleton_img = load_image(skeleton_img)\n",
    "    \n",
    "    input_data = [reference_fg, ref_bg_image, skeleton_img]\n",
    "    output_image = trainer.eval_demo_run_masked(input_data, eval_dataset=eval_dataset)\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0580155a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a1454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c3b8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangtan/anaconda3/envs/disco/lib/python3.8/site-packages/gradio/layouts.py:80: UserWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  warnings.warn(\n",
      "/home/wangtan/anaconda3/envs/disco/lib/python3.8/site-packages/gradio/blocks.py:261: UserWarning: api_name load_example already exists, using load_example_1\n",
      "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
      "/home/wangtan/anaconda3/envs/disco/lib/python3.8/site-packages/gradio/blocks.py:261: UserWarning: api_name load_example already exists, using load_example_2\n",
      "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://e4ec2a4f33f5ee858d.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://e4ec2a4f33f5ee858d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode [all]: There are 686 modules in unet to be set as requires_grad=True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 12.48it/s]\n"
     ]
    }
   ],
   "source": [
    "#### Launch the gradio demo\n",
    "\n",
    "import gradio as gr\n",
    "'''\n",
    "launch app\n",
    "'''\n",
    "title = \"DisCo Demo (Video Demo Comming Soon!)\"\n",
    "description = \"\"\"<p style='text-align: center'> <a href='https://disco-dance.github.io/' target='_blank'>Project Page</a> | <a href='https://arxiv.org/pdf/2212.11270.pdf' target='_blank'>Paper</a> | <a href='https://github.com/microsoft/X-Decoder' target='_blank'>Github Repo</a> | <a href='https://youtu.be/wYp6vmyolqE' target='_blank'>Video</a> </p>\n",
    "<p>Skip the queue by duplicating this space and upgrading to GPU in settings</p>\n",
    "<a href=\"https://huggingface.co/spaces/xdecoder/Demo?duplicate=true\"><img src=\"https://bit.ly/3gLdBN6\" alt=\"Duplicate Space\"></a>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    # DisCo Demo (Video Demo Comming Soon!)\n",
    "    Start edit the human with provided human foreground, background, pose. \n",
    "    \n",
    "    Note that for self-uploaded images, TikTok-Style human images are preferred.\n",
    "    \n",
    "    [Project Page](https://disco-dance.github.io/) | [Github](https://github.com/Wangt-CN/DisCo)\n",
    "    \"\"\")\n",
    "    #     gr.Markdown(\n",
    "#     \"\"\"\n",
    "#     ## DisCo Demo (Video Demo Comming Soon!)\n",
    "#     <p style='text-align: center'> <a href='https://disco-dance.github.io/' target='_blank'>Project Page</a> | <a href='https://arxiv.org/pdf/2212.11270.pdf' target='_blank'>Paper</a> | <a href='https://github.com/microsoft/X-Decoder' target='_blank'>Github Repo</a> | <a href='https://youtu.be/wYp6vmyolqE' target='_blank'>Video</a> </p>\n",
    "# <p>Skip the queue by duplicating this space and upgrading to GPU in settings</p>\n",
    "# <a href=\"https://huggingface.co/spaces/xdecoder/Demo?duplicate=true\"><img src=\"https://bit.ly/3gLdBN6\" alt=\"Duplicate Space\"></a>\n",
    "#     \"\"\")\n",
    "    \n",
    "    with gr.Row().style(equal_height=False):\n",
    "        with gr.Column(min_width=400, scale=2):\n",
    "            input_fg = gr.Image(type='pil',label=\"Foreground Image\")\n",
    "            gr.Examples(examples=[\"./demo_data/fg/masked_images/00035.png\", \"./demo_data/fg/masked_images/00335.png\", \"./demo_data/fg/masked_images/00147.png\", \"./demo_data/fg/masked_images/00072.png\", \"./demo_data/fg/masked_images/00115.png\"], inputs=input_fg)\n",
    "\n",
    "            input_bg = gr.Image(type='pil',label=\"Background Image\")\n",
    "            gr.Examples(examples=[\"./demo_data/bg/masked_images/00035.png\", \"./demo_data/bg/masked_images/00335.png\", \"./demo_data/bg/masked_images/00147.png\", \"./demo_data/bg/masked_images/00072.png\", \"./demo_data/bg/masked_images/00115.png\"], inputs=input_bg)\n",
    "\n",
    "            input_pose = gr.Image(type='pil',label=\"Target Pose\",scale=1)\n",
    "            gr.Examples(examples=[\"./demo_data/pose_img/0049.png\",\"./demo_data/pose_img/0198.png\",\"./demo_data/pose_img/0213.png\",\"./demo_data/pose_img/0264.png\",\"./demo_data/pose_img/0144.png\",\"./demo_data/pose_img/0054.png\"], inputs=input_pose)\n",
    "\n",
    "            btn = gr.Button(\"Generate\")\n",
    "            \n",
    "    \n",
    "        with gr.Column(min_width=150):\n",
    "            output_img = gr.Image(type='pil',label=\"Edited Human Image\")\n",
    "        \n",
    "    btn.click(inference_masked, inputs=[input_fg, input_bg, input_pose], outputs=[output_img])\n",
    "    \n",
    "demo.queue(concurrency_count=2)\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141af2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_hackathon2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
