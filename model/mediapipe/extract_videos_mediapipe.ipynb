{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT 4: \n",
    "FACEMESH_TESSELATION: This connection type is used to draw the tesselation of the face. It outlines the overall structure and shape of the face.\n",
    "\n",
    "FACEMESH_CONTOURS: These connections are used to outline the contours of the face, such as the jawline, lips, and eyes.\n",
    "\n",
    "FACEMESH_IRISES: This type specifically focuses on the landmarks around the irises, allowing for detailed rendering of the eye region.\n",
    "\n",
    "When using MediaPipe Face Mesh in Python, these\n",
    "\n",
    "\n",
    "https://mediapipe.readthedocs.io/en/latest/solutions/face_mesh.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "def extract_coordinates():\n",
    "    rows = []\n",
    "    #creating empty file in folder, I added the start_time in the name of the csv file, so that if a symbol appears many times in a video, it will still be created in two different csv files, just that they will have different starting times\n",
    "    # csv_file = f\"demo.csv\"\n",
    "    # if os.path.exists(csv_file):\n",
    "    #     return \n",
    "\n",
    "\n",
    "\n",
    "# Setup CSV File for the videos\n",
    "# 21 right hand landmarks, 21 left hand landmarks, 33 pose landmarks\n",
    "    # num_coords = 21 + 21 + 33\n",
    "    # landmarks = []\n",
    "    # for val in range(1, num_coords+1):\n",
    "    #     landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]\n",
    "    # print(\"Initialized an empty landmarks of size:\", len(landmarks))\n",
    "\n",
    "    # with open(csv_file, mode='w', newline='') as f:\n",
    "    #     csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    #     csv_writer.writerow(landmarks)\n",
    "    \n",
    "    #size of the videos: \n",
    "    # (640, 480)\n",
    "    size = (640, 480)\n",
    "    # # that mp4 doesn't work :)\n",
    "    # final_vid = cv2.VideoWriter('test.mp4', cv2.VideoWriter.fourcc(*'MP4V'), 10, size)\n",
    "    final_vid = cv2.VideoWriter('test.avi',  \n",
    "                         cv2.VideoWriter_fourcc(*'MJPG'), \n",
    "                         10, size)\n",
    "\n",
    "#created graph with body landmark connections.\n",
    "    bodyConnect = [(0, 1), (1, 2), (2, 3), (3, 7), (0, 4), (4, 5), (5, 6), (6, 8), \n",
    "    # (10, 24), (9, 23), these are the the middle stuff \n",
    "    (12, 14), (14, 20), (11, 13), (13, 19), \n",
    "    (24, 26), (26, 28), (23, 25), (25, 27), \n",
    "    (12, 11)]\n",
    "\n",
    "# https://github.com/rcsmit/python_scripts_rcsmit/blob/master/extras/Gal_Gadot_by_Gage_Skidmore_4_5000x5921_annotated_black_letters.jpg\n",
    "    # faceConnect = [(234, 93), (93, 132), (132, 58), (58, 172), (172, 136), (136, 150), \n",
    "    # (150, 149), (149, 176), (176, 148), (148, 152), (152,377), \n",
    "    # (377, 400), (400, 378), (378, 379), (379, 365), (365, 397), (397, 367), \n",
    "    # (367, 288), (288, 435), (435, 361), (361, 401), (401, 323), (323, 366), (366, 451), #face contours\n",
    "    # (57, 77), (77, 89), (89, 88), (88, 178), (178, 87), (87, 14), (14, 317), (402, 319), (319, 307), #mouth\n",
    "    # (64, 59), (59, 44), (44, 1), (1, 457), (457, 294),  #straight nose\n",
    "    # (1, 4), (4, 5), (5, 195), (195, 197), (197, 6), (6, 168), (168, 8),  #vertical up\n",
    "    # (190, 222), (222, 224), (224, 124), #left eye\n",
    "    # (413, 441), (441, 442), (442, 443), (443, 445) #right eye\n",
    "    # ]\n",
    "    # faceConnect = []\n",
    "\n",
    "#working with each video\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    # cap = cv2.VideoCapture(\"moonwalk.mp4\")\n",
    "    if (cap.isOpened()== False): \n",
    "        print(\"Error opening video stream or file\")\n",
    "    # Read until video is completed\n",
    "    else: \n",
    "        with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "            while(cap.isOpened()):  \n",
    "                # Capture frame-by-frame\n",
    "                ret, image = cap.read() \n",
    "                if ret == True:\n",
    "                    # the BGR image to RGB.\n",
    "                    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "                    # To improve performance, optionally mark the image as not writeable to\n",
    "                    # pass by reference.\n",
    "                    image.flags.writeable = False\n",
    "\n",
    "                    #!results contains all the information about the image, in this case, we are looking at hands\n",
    "                    results = holistic.process(image)\n",
    "                    \n",
    "                    \n",
    "                    # Draw the hand annotations on the image.\n",
    "                    image.flags.writeable = True\n",
    "                    # image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                    #creating a black background.\n",
    "                    image = np.zeros(image.shape , np.uint8)\n",
    "                    \n",
    "                    # Display the resulting frame\n",
    "                    # Right hand\n",
    "                    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                            mp_drawing.DrawingSpec(color=(80,22,10), thickness=1, circle_radius=1),\n",
    "                                            mp_drawing.DrawingSpec(color=(80,44,121), thickness=1, circle_radius=1)\n",
    "                                            )\n",
    "\n",
    "                    # Left Hand\n",
    "                    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                            mp_drawing.DrawingSpec(color=(121,22,76), thickness=1, circle_radius=1),\n",
    "                                            mp_drawing.DrawingSpec(color=(121,44,250), thickness=1, circle_radius=1)\n",
    "                                            )\n",
    "\n",
    "                    # Pose Detections\n",
    "                    mp_drawing.draw_landmarks(image,  results.pose_landmarks, bodyConnect,# mp_holistic.POSE_CONNECTIONS, \n",
    "                                            mp_drawing.DrawingSpec(color=(245,117,66), thickness=1, circle_radius=1),\n",
    "                                            mp_drawing.DrawingSpec(color=(245,66,230), thickness=1, circle_radius=1)\n",
    "                                            )\n",
    "                    \n",
    "                    # mp_drawing.draw_landmarks(image, results.face_landmarks, mp_face_mesh.FACEMESH_TESSELATION, #mp_holistic.FACEMESH_CONTOURS,#mp_face_mesh.FACEMESH_IRISES,  \n",
    "                    #                         mp_drawing.DrawingSpec(color=(80,22,10), thickness=1, circle_radius=1),\n",
    "                    #                         mp_drawing.DrawingSpec(color=(80,44,121), thickness=1, circle_radius=1)\n",
    "                    #                         )\n",
    "\n",
    "\n",
    "                    cv2.imshow('Frame',image)\n",
    "\n",
    "                    #writing into the video.\n",
    "                    final_vid.write(image) \n",
    "\n",
    "\n",
    "\n",
    "                    # Press Q on keyboard to  exitx\n",
    "                    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                        # frame_width = int(cap.get(3)) \n",
    "                        # frame_height = int(cap.get(4)) \n",
    "                        \n",
    "                        # size = (frame_width, frame_height) \n",
    "                        # result = cv2.VideoWriter('test.mp4',  \n",
    "                        #  cv2.VideoWriter_fourcc(*'MP4V'), \n",
    "                        #  10, size) \n",
    "                        print(size)\n",
    "                        break\n",
    "                    # Export coordinates\n",
    "                    # try:\n",
    "                    #     # Extract Pose landmarks\n",
    "                    #     if results.pose_landmarks:\n",
    "                    #         pose = results.pose_landmarks.landmark\n",
    "                    #         pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "                    #     else:\n",
    "                    #         # continue\n",
    "                    #         pose_row=list(np.array([[0,0,0,0] for i in range(33)]).flatten())\n",
    "                    #     # Extract hands landmarks\n",
    "                    #     if results.right_hand_landmarks:\n",
    "                    #         right_hand = results.right_hand_landmarks.landmark\n",
    "                    #         right_hand_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in right_hand]).flatten())\n",
    "                    #     else:\n",
    "                    #         #If no right hand detected, then it writes 0 to the CSV file\n",
    "                    #         right_hand_row = list(np.array([[0,0,0,0] for i in range(21)]).flatten())\n",
    "                    #     if results.left_hand_landmarks:\n",
    "                    #         left_hand = results.left_hand_landmarks.landmark\n",
    "                    #         left_hand_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in left_hand]).flatten())\n",
    "                    #     else:\n",
    "                    #         #If no left hand detected, then it writes 0 to the CSV file\n",
    "                    #         left_hand_row = list(np.array([[0,0,0,0] for i in range(21)]).flatten())\n",
    "\n",
    "                    #     # Concate rows\n",
    "                    #     row = pose_row + right_hand_row + left_hand_row\n",
    "                    #     rows.append(row)\n",
    "\n",
    "                        # Export to CSV\n",
    "                        \n",
    "\n",
    "                    # except Exception as e:\n",
    "                    #     print(e)\n",
    "                    #     break\n",
    "                         \n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            # When everything done, release the video capture object\n",
    "            cap.release() \n",
    "\n",
    "            #this saves into the video\n",
    "            final_vid.release()\n",
    "\n",
    "\n",
    "            # Closes all the frames\n",
    "            cv2.destroyAllWindows()\n",
    "            # with open(csv_file, mode='a', newline='') as f:\n",
    "            #                 csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            #                 for row in rows:\n",
    "            #                     csv_writer.writerow(row) \n",
    "            # return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 480)\n"
     ]
    }
   ],
   "source": [
    "extract_coordinates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.0-6ubuntu1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 13 (Ubuntu 13.2.0-2ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=6ubuntu1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libglslang --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librist --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --disable-sndio --enable-libjxl --enable-pocketsphinx --enable-librsvg --enable-libvpl --disable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-libplacebo --enable-librav1e --enable-shared\n",
      "  libavutil      58.  2.100 / 58.  2.100\n",
      "  libavcodec     60.  3.100 / 60.  3.100\n",
      "  libavformat    60.  3.100 / 60.  3.100\n",
      "  libavdevice    60.  1.100 / 60.  1.100\n",
      "  libavfilter     9.  3.100 /  9.  3.100\n",
      "  libswscale      7.  1.100 /  7.  1.100\n",
      "  libswresample   4. 10.100 /  4. 10.100\n",
      "  libpostproc    57.  1.100 / 57.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'output.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.3.100\n",
      "  Duration: 00:00:05.30, start: 0.000000, bitrate: 284 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuvj420p(pc, bt470bg/unknown/unknown, progressive), 640x480, 146 kb/s, 10 fps, 10 tbr, 10240 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.3.100 libx264\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x55f08f96f100] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x55f08f96f100] \u001b[0mprofile High, level 2.1, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x55f08f96f100] \u001b[0m264 - core 164 r3095 baee400 - H.264/MPEG-4 AVC codec - Copyleft 2003-2022 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=10 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'output4.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.3.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuvj420p(pc, bt470bg/unknown/unknown, progressive), 290x480, q=2-31, 10 fps, 10240 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.3.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=   53 fps=0.0 q=-1.0 Lsize=      94kB time=00:00:05.00 bitrate= 153.3kbits/s dup=1 drop=0 speed=30.6x    \n",
      "video:92kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.547463%\n",
      "\u001b[1;36m[libx264 @ 0x55f08f96f100] \u001b[0mframe I:1     Avg QP:17.90  size:  3032\n",
      "\u001b[1;36m[libx264 @ 0x55f08f96f100] \u001b[0mframe P:18    Avg QP:21.02  size:  2337\n",
      "\u001b[1;36m[libx264 @ 0x55f08f96f100] \u001b[0mframe B:34    Avg QP:24.80  size:  1428\n",
      "\u001b[1;36m[libx264 @ 0x55f08f96f100] \u001b[0mconsecutive B-frames:  9.4%  7.5% 22.6% 60.4%\n",
      "\u001b[1;36m[libx264 @ 0x55f08f96f100] \u001b[0mmb I  I16..4: 17.0% 70.9% 12.1%\n",
      "\u001b[1;36m[libx264 @ 0x55f08f96f100] \u001b[0mmb P  I16..4:  1.8%  5.7%  4.6%  P16..4:  7.7%  3.9%  1.4%  0.0%  0.0%    skip:75.0%\n",
      "\u001b[1;36m[libx264 @ 0x55f08f96f100] \u001b[0mmb B  I16..4:  0.7%  0.2%  1.4%  B16..8: 13.4%  5.1%  0.7%  direct: 1.0%  skip:77.5%  L0:54.0% L1:44.2% BI: 1.8%\n",
      "\u001b[1;36m[libx264 @ 0x55f08f96f100] \u001b[0m8x8 transform intra:45.2% inter:15.1%\n",
      "\u001b[1;36m[libx264 @ 0x55f08f96f100] \u001b[0mcoded y,uvDC,uvAC intra: 23.6% 48.3% 44.3% inter: 2.3% 6.4% 4.7%\n",
      "\u001b[1;36m[libx264 @ 0x55f08f96f100] \u001b[0mi16 v,h,dc,p: 74% 18%  7%  1%\n",
      "\u001b[1;36m[libx264 @ 0x55f08f96f100] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 29%  9% 61%  0%  0%  0%  0%  0%  0%\n",
      "\u001b[1;36m[libx264 @ 0x55f08f96f100] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 21% 15% 40%  5%  5%  4%  3%  3%  2%\n",
      "\u001b[1;36m[libx264 @ 0x55f08f96f100] \u001b[0mi8c dc,h,v,p: 64% 14% 21%  1%\n",
      "\u001b[1;36m[libx264 @ 0x55f08f96f100] \u001b[0mWeighted P-Frames: Y:5.6% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x55f08f96f100] \u001b[0mref P L0: 49.4% 21.4% 17.8% 10.9%  0.5%\n",
      "\u001b[1;36m[libx264 @ 0x55f08f96f100] \u001b[0mref B L0: 87.2% 10.2%  2.6%\n",
      "\u001b[1;36m[libx264 @ 0x55f08f96f100] \u001b[0mref B L1: 96.6%  3.4%\n",
      "\u001b[1;36m[libx264 @ 0x55f08f96f100] \u001b[0mkb/s:141.37\n"
     ]
    }
   ],
   "source": [
    "# !ffmpeg -i  test.avi   test.mp4\n",
    "# trimming the video from second 2 to 6\n",
    "# !ffmpeg -ss 5 -to 10 -i test.mp4 -c copy output.mp4\n",
    "# !ffmpeg -ss 158 -to 163 -i moowalkyt.mp4 -c copy moonwalkytcut.mp4\n",
    "\n",
    "# cropping 150 pixels each side\n",
    "\n",
    "#this is more narrow\n",
    "# !ffmpeg -i output.mp4 -vf \"crop=in_w-300:in_h:150:0\" output3.mp4\n",
    "\n",
    "#this is more wide\n",
    "# !ffmpeg -i output.mp4 -vf \"crop=in_w-200:in_h:200:0\" output2.mp4\n",
    "\n",
    "#this is more more narrow\n",
    "# !ffmpeg -i output.mp4 -vf \"crop=in_w-350:in_h:100:0\" output4.mp4\n",
    "\n",
    "# !ffmpeg -i moonwalkytcut.mp4 -vf \"crop=in_w-350:in_h:150:0\" moonwalk.mp4\n",
    "\n",
    "!ffmpeg -i output.mp4 -vf \"crop=in_w-350:in_h:150:0\" output4.mp4\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280x720\n"
     ]
    }
   ],
   "source": [
    "# get size\n",
    "!ffprobe -v error -select_streams v:0 -show_entries stream=width,height -of csv=s=x:p=0 moowalkyt.mp4\n",
    "\n",
    "#this is the size of my videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cropping the youtube video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListNode:\n",
    "    def __init__(self, value=0, next=None):\n",
    "        self.value = value\n",
    "        self.next = next\n",
    "\n",
    "def reverse_linked_list(lst):\n",
    "    new_lst = None\n",
    "    while lst != None:\n",
    "        temp_list = ListNode(lst.value, new_lst)\n",
    "        new_lst = temp_list\n",
    "        lst = lst.next\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-hackathons",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
