{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT 4: \n",
    "FACEMESH_TESSELATION: This connection type is used to draw the tesselation of the face. It outlines the overall structure and shape of the face.\n",
    "\n",
    "FACEMESH_CONTOURS: These connections are used to outline the contours of the face, such as the jawline, lips, and eyes.\n",
    "\n",
    "FACEMESH_IRISES: This type specifically focuses on the landmarks around the irises, allowing for detailed rendering of the eye region.\n",
    "\n",
    "When using MediaPipe Face Mesh in Python, these\n",
    "\n",
    "\n",
    "https://mediapipe.readthedocs.io/en/latest/solutions/face_mesh.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "def extract_coordinates():\n",
    "    rows = []\n",
    "    #creating empty file in folder, I added the start_time in the name of the csv file, so that if a symbol appears many times in a video, it will still be created in two different csv files, just that they will have different starting times\n",
    "    # csv_file = f\"demo.csv\"\n",
    "    # if os.path.exists(csv_file):\n",
    "    #     return \n",
    "\n",
    "\n",
    "\n",
    "# Setup CSV File for the videos\n",
    "# 21 right hand landmarks, 21 left hand landmarks, 33 pose landmarks\n",
    "    # num_coords = 21 + 21 + 33\n",
    "    # landmarks = []\n",
    "    # for val in range(1, num_coords+1):\n",
    "    #     landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]\n",
    "    # print(\"Initialized an empty landmarks of size:\", len(landmarks))\n",
    "\n",
    "    # with open(csv_file, mode='w', newline='') as f:\n",
    "    #     csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    #     csv_writer.writerow(landmarks)\n",
    "    \n",
    "    #size of the videos: \n",
    "    # (640, 480)\n",
    "    size = (640, 480)\n",
    "    # # that mp4 doesn't work :)\n",
    "    # final_vid = cv2.VideoWriter('test.mp4', cv2.VideoWriter.fourcc(*'MP4V'), 10, size)\n",
    "    final_vid = cv2.VideoWriter('test.avi',  \n",
    "                         cv2.VideoWriter_fourcc(*'MJPG'), \n",
    "                         10, size)\n",
    "\n",
    "#created graph with body landmark connections.\n",
    "    bodyConnect = [(0, 1), (1, 2), (2, 3), (3, 7), (0, 4), (4, 5), (5, 6), (6, 8), \n",
    "    # (10, 24), (9, 23), these are the the middle stuff \n",
    "    (12, 14), (14, 20), (11, 13), (13, 19), \n",
    "    (24, 26), (26, 28), (23, 25), (25, 27), \n",
    "    (12, 11)]\n",
    "\n",
    "# https://github.com/rcsmit/python_scripts_rcsmit/blob/master/extras/Gal_Gadot_by_Gage_Skidmore_4_5000x5921_annotated_black_letters.jpg\n",
    "    # faceConnect = [(234, 93), (93, 132), (132, 58), (58, 172), (172, 136), (136, 150), \n",
    "    # (150, 149), (149, 176), (176, 148), (148, 152), (152,377), \n",
    "    # (377, 400), (400, 378), (378, 379), (379, 365), (365, 397), (397, 367), \n",
    "    # (367, 288), (288, 435), (435, 361), (361, 401), (401, 323), (323, 366), (366, 451), #face contours\n",
    "    # (57, 77), (77, 89), (89, 88), (88, 178), (178, 87), (87, 14), (14, 317), (402, 319), (319, 307), #mouth\n",
    "    # (64, 59), (59, 44), (44, 1), (1, 457), (457, 294),  #straight nose\n",
    "    # (1, 4), (4, 5), (5, 195), (195, 197), (197, 6), (6, 168), (168, 8),  #vertical up\n",
    "    # (190, 222), (222, 224), (224, 124), #left eye\n",
    "    # (413, 441), (441, 442), (442, 443), (443, 445) #right eye\n",
    "    # ]\n",
    "    # faceConnect = []\n",
    "\n",
    "#working with each video\n",
    "    # cap = cv2.VideoCapture(0)\n",
    "    cap = cv2.VideoCapture(\"Stationary_moonwalk-yt.mp4\")\n",
    "    if (cap.isOpened()== False): \n",
    "        print(\"Error opening video stream or file\")\n",
    "    # Read until video is completed\n",
    "    else: \n",
    "        with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "            while(cap.isOpened()):  \n",
    "                # Capture frame-by-frame\n",
    "                ret, image = cap.read() \n",
    "                if ret == True:\n",
    "                    # the BGR image to RGB.\n",
    "                    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "                    # To improve performance, optionally mark the image as not writeable to\n",
    "                    # pass by reference.\n",
    "                    image.flags.writeable = False\n",
    "\n",
    "                    #!results contains all the information about the image, in this case, we are looking at hands\n",
    "                    results = holistic.process(image)\n",
    "                    \n",
    "                    \n",
    "                    # Draw the hand annotations on the image.\n",
    "                    image.flags.writeable = True\n",
    "                    # image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                    #creating a black background.\n",
    "                    image = np.zeros(image.shape , np.uint8)\n",
    "                    \n",
    "                    # Display the resulting frame\n",
    "                    # Right hand\n",
    "                    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                            mp_drawing.DrawingSpec(color=(80,22,10), thickness=1, circle_radius=1),\n",
    "                                            mp_drawing.DrawingSpec(color=(80,44,121), thickness=1, circle_radius=1)\n",
    "                                            )\n",
    "\n",
    "                    # Left Hand\n",
    "                    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                            mp_drawing.DrawingSpec(color=(121,22,76), thickness=1, circle_radius=1),\n",
    "                                            mp_drawing.DrawingSpec(color=(121,44,250), thickness=1, circle_radius=1)\n",
    "                                            )\n",
    "\n",
    "                    # Pose Detections\n",
    "                    mp_drawing.draw_landmarks(image,  results.pose_landmarks, bodyConnect,# mp_holistic.POSE_CONNECTIONS, \n",
    "                                            mp_drawing.DrawingSpec(color=(245,117,66), thickness=1, circle_radius=1),\n",
    "                                            mp_drawing.DrawingSpec(color=(245,66,230), thickness=1, circle_radius=1)\n",
    "                                            )\n",
    "                    \n",
    "                    # mp_drawing.draw_landmarks(image, results.face_landmarks, mp_face_mesh.FACEMESH_TESSELATION, #mp_holistic.FACEMESH_CONTOURS,#mp_face_mesh.FACEMESH_IRISES,  \n",
    "                    #                         mp_drawing.DrawingSpec(color=(80,22,10), thickness=1, circle_radius=1),\n",
    "                    #                         mp_drawing.DrawingSpec(color=(80,44,121), thickness=1, circle_radius=1)\n",
    "                    #                         )\n",
    "\n",
    "\n",
    "                    cv2.imshow('Frame',image)\n",
    "\n",
    "                    #writing into the video.\n",
    "                    final_vid.write(image) \n",
    "\n",
    "\n",
    "\n",
    "                    # Press Q on keyboard to  exitx\n",
    "                    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                        # frame_width = int(cap.get(3)) \n",
    "                        # frame_height = int(cap.get(4)) \n",
    "                        \n",
    "                        # size = (frame_width, frame_height) \n",
    "                        # result = cv2.VideoWriter('test.mp4',  \n",
    "                        #  cv2.VideoWriter_fourcc(*'MP4V'), \n",
    "                        #  10, size) \n",
    "                        print(size)\n",
    "                        break\n",
    "                    # Export coordinates\n",
    "                    # try:\n",
    "                    #     # Extract Pose landmarks\n",
    "                    #     if results.pose_landmarks:\n",
    "                    #         pose = results.pose_landmarks.landmark\n",
    "                    #         pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "                    #     else:\n",
    "                    #         # continue\n",
    "                    #         pose_row=list(np.array([[0,0,0,0] for i in range(33)]).flatten())\n",
    "                    #     # Extract hands landmarks\n",
    "                    #     if results.right_hand_landmarks:\n",
    "                    #         right_hand = results.right_hand_landmarks.landmark\n",
    "                    #         right_hand_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in right_hand]).flatten())\n",
    "                    #     else:\n",
    "                    #         #If no right hand detected, then it writes 0 to the CSV file\n",
    "                    #         right_hand_row = list(np.array([[0,0,0,0] for i in range(21)]).flatten())\n",
    "                    #     if results.left_hand_landmarks:\n",
    "                    #         left_hand = results.left_hand_landmarks.landmark\n",
    "                    #         left_hand_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in left_hand]).flatten())\n",
    "                    #     else:\n",
    "                    #         #If no left hand detected, then it writes 0 to the CSV file\n",
    "                    #         left_hand_row = list(np.array([[0,0,0,0] for i in range(21)]).flatten())\n",
    "\n",
    "                    #     # Concate rows\n",
    "                    #     row = pose_row + right_hand_row + left_hand_row\n",
    "                    #     rows.append(row)\n",
    "\n",
    "                        # Export to CSV\n",
    "                        \n",
    "\n",
    "                    # except Exception as e:\n",
    "                    #     print(e)\n",
    "                    #     break\n",
    "                         \n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            # When everything done, release the video capture object\n",
    "            cap.release() \n",
    "\n",
    "            #this saves into the video\n",
    "            final_vid.release()\n",
    "\n",
    "\n",
    "            # Closes all the frames\n",
    "            cv2.destroyAllWindows()\n",
    "            # with open(csv_file, mode='a', newline='') as f:\n",
    "            #                 csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            #                 for row in rows:\n",
    "            #                     csv_writer.writerow(row) \n",
    "            # return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error opening video stream or file\n"
     ]
    }
   ],
   "source": [
    "extract_coordinates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.0-6ubuntu1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 13 (Ubuntu 13.2.0-2ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=6ubuntu1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libglslang --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librist --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --disable-sndio --enable-libjxl --enable-pocketsphinx --enable-librsvg --enable-libvpl --disable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-libplacebo --enable-librav1e --enable-shared\n",
      "  libavutil      58.  2.100 / 58.  2.100\n",
      "  libavcodec     60.  3.100 / 60.  3.100\n",
      "  libavformat    60.  3.100 / 60.  3.100\n",
      "  libavdevice    60.  1.100 / 60.  1.100\n",
      "  libavfilter     9.  3.100 /  9.  3.100\n",
      "  libswscale      7.  1.100 /  7.  1.100\n",
      "  libswresample   4. 10.100 /  4. 10.100\n",
      "  libpostproc    57.  1.100 / 57.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'test.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.3.100\n",
      "  Duration: 00:00:31.10, start: 0.000000, bitrate: 91 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuvj420p(pc, bt470bg/unknown/unknown, progressive), 640x480, 90 kb/s, 10 fps, 10 tbr, 10240 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.3.100 libx264\n",
      "Output #0, mp4, to 'output.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.3.100\n",
      "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuvj420p(pc, bt470bg/unknown/unknown, progressive), 640x480, q=2-31, 90 kb/s, 10 fps, 10 tbr, 10240 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.3.100 libx264\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "frame=  119 fps=0.0 q=-1.0 Lsize=     164kB time=00:00:04.90 bitrate= 274.1kbits/s speed= 953x    \n",
      "video:162kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.348806%\n",
      "ffmpeg version 6.0-6ubuntu1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 13 (Ubuntu 13.2.0-2ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=6ubuntu1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libglslang --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librist --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --disable-sndio --enable-libjxl --enable-pocketsphinx --enable-librsvg --enable-libvpl --disable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-libplacebo --enable-librav1e --enable-shared\n",
      "  libavutil      58.  2.100 / 58.  2.100\n",
      "  libavcodec     60.  3.100 / 60.  3.100\n",
      "  libavformat    60.  3.100 / 60.  3.100\n",
      "  libavdevice    60.  1.100 / 60.  1.100\n",
      "  libavfilter     9.  3.100 /  9.  3.100\n",
      "  libswscale      7.  1.100 /  7.  1.100\n",
      "  libswresample   4. 10.100 /  4. 10.100\n",
      "  libpostproc    57.  1.100 / 57.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'output.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.3.100\n",
      "  Duration: 00:00:05.40, start: 0.000000, bitrate: 248 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuvj420p(pc, bt470bg/unknown/unknown, progressive), 640x480, 111 kb/s, 10 fps, 10 tbr, 10240 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.3.100 libx264\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x557c4c67cdc0] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x557c4c67cdc0] \u001b[0mprofile High, level 2.1, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x557c4c67cdc0] \u001b[0m264 - core 164 r3095 baee400 - H.264/MPEG-4 AVC codec - Copyleft 2003-2022 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=10 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'output4.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.3.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuvj420p(pc, bt470bg/unknown/unknown, progressive), 290x480, q=2-31, 10 fps, 10240 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.3.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=   54 fps=0.0 q=-1.0 Lsize=      72kB time=00:00:05.10 bitrate= 114.9kbits/s dup=2 drop=0 speed=32.5x    \n",
      "video:70kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.072770%\n",
      "\u001b[1;36m[libx264 @ 0x557c4c67cdc0] \u001b[0mframe I:1     Avg QP: 8.74  size:  2988\n",
      "\u001b[1;36m[libx264 @ 0x557c4c67cdc0] \u001b[0mframe P:17    Avg QP:18.21  size:  1892\n",
      "\u001b[1;36m[libx264 @ 0x557c4c67cdc0] \u001b[0mframe B:36    Avg QP:22.62  size:   999\n",
      "\u001b[1;36m[libx264 @ 0x557c4c67cdc0] \u001b[0mconsecutive B-frames:  5.6% 11.1% 16.7% 66.7%\n",
      "\u001b[1;36m[libx264 @ 0x557c4c67cdc0] \u001b[0mmb I  I16..4: 87.7%  1.1% 11.2%\n",
      "\u001b[1;36m[libx264 @ 0x557c4c67cdc0] \u001b[0mmb P  I16..4:  1.4%  3.9%  3.0%  P16..4:  7.5%  4.0%  1.2%  0.0%  0.0%    skip:79.0%\n",
      "\u001b[1;36m[libx264 @ 0x557c4c67cdc0] \u001b[0mmb B  I16..4:  0.2%  0.1%  0.6%  B16..8: 11.9%  3.6%  0.7%  direct: 0.6%  skip:82.2%  L0:51.3% L1:46.2% BI: 2.4%\n",
      "\u001b[1;36m[libx264 @ 0x557c4c67cdc0] \u001b[0m8x8 transform intra:25.5% inter:13.8%\n",
      "\u001b[1;36m[libx264 @ 0x557c4c67cdc0] \u001b[0mcoded y,uvDC,uvAC intra: 19.7% 46.0% 42.5% inter: 1.6% 5.1% 4.0%\n",
      "\u001b[1;36m[libx264 @ 0x557c4c67cdc0] \u001b[0mi16 v,h,dc,p: 89%  8%  3%  0%\n",
      "\u001b[1;36m[libx264 @ 0x557c4c67cdc0] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 16% 15% 67%  0%  0%  0%  0%  0%  0%\n",
      "\u001b[1;36m[libx264 @ 0x557c4c67cdc0] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 22% 15% 40%  4%  5%  4%  5%  3%  2%\n",
      "\u001b[1;36m[libx264 @ 0x557c4c67cdc0] \u001b[0mi8c dc,h,v,p: 63% 15% 21%  0%\n",
      "\u001b[1;36m[libx264 @ 0x557c4c67cdc0] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x557c4c67cdc0] \u001b[0mref P L0: 53.0% 20.9% 16.3%  9.8%\n",
      "\u001b[1;36m[libx264 @ 0x557c4c67cdc0] \u001b[0mref B L0: 85.8% 11.7%  2.5%\n",
      "\u001b[1;36m[libx264 @ 0x557c4c67cdc0] \u001b[0mref B L1: 95.4%  4.6%\n",
      "\u001b[1;36m[libx264 @ 0x557c4c67cdc0] \u001b[0mkb/s:105.33\n"
     ]
    }
   ],
   "source": [
    "# !ffmpeg -i  test.avi   test.mp4\n",
    "# # trimming the video from second 2 to 6\n",
    "!ffmpeg -ss 22 -to 27 -i test.mp4 -c copy output.mp4\n",
    "\n",
    "# cropping 150 pixels each side\n",
    "\n",
    "#this is more narrow\n",
    "# !ffmpeg -i output.mp4 -vf \"crop=in_w-300:in_h:150:0\" output3.mp4\n",
    "\n",
    "#this is more wide\n",
    "# !ffmpeg -i output.mp4 -vf \"crop=in_w-200:in_h:200:0\" output2.mp4\n",
    "\n",
    "#this is more more narrow\n",
    "# !ffmpeg -i output.mp4 -vf \"crop=in_w-350:in_h:100:0\" output4.mp4\n",
    "\n",
    "!ffmpeg -i output.mp4 -vf \"crop=in_w-350:in_h:150:0\" output4.mp4\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290x480\n"
     ]
    }
   ],
   "source": [
    "# get size\n",
    "!ffprobe -v error -select_streams v:0 -show_entries stream=width,height -of csv=s=x:p=0 output4.mp4\n",
    "\n",
    "#this is the size of my videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cropping the youtube video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListNode:\n",
    "    def __init__(self, value=0, next=None):\n",
    "        self.value = value\n",
    "        self.next = next\n",
    "\n",
    "def reverse_linked_list(lst):\n",
    "    new_lst = None\n",
    "    while lst != None:\n",
    "        temp_list = ListNode(lst.value, new_lst)\n",
    "        new_lst = temp_list\n",
    "        lst = lst.next\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-hackathons",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
